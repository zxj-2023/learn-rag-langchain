{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# æµå¼ä¼ è¾“\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "æµå¼ä¼ è¾“å¯ä»¥å‡å°‘æ•°æ®ç”Ÿæˆä¸ç”¨æˆ·æ¥æ”¶ä¹‹é—´çš„å»¶è¿Ÿã€‚\n",
    "åœ¨ Agent ä¸­å¸¸ç”¨ä¸¤ç§ç±»å‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## è®¾ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "åŠ è½½å¹¶/æˆ–æ£€æŸ¥æ‰€éœ€çš„ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DASHSCOPE_API_KEY=****0fbe\n",
      "DASHSCOPE_BASE_URL=****e/v1\n",
      "LANGSMITH_API_KEY=****5ced\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# ä» .env åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# æ£€æŸ¥å¹¶æ‰“å°ç»“æœ\n",
    "doublecheck_env(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_qwq import ChatQwen\n",
    "import os\n",
    "llm=ChatQwen(\n",
    "    model=\"qwen3-max\",\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## ä¸ä½¿ç”¨æµå¼ï¼ˆinvokeï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m a fullâ€‘stack comedian: my frontend jokes get laughs, my backend jokes return a 500. \n",
      "\n",
      "Want another?\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values æ¨¡å¼\n",
    "ä½ å·²ç»åœ¨ä¹‹å‰çš„ç¤ºä¾‹ä¸­çœ‹åˆ°è¿‡è¿™ç§æµå¼æ¨¡å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "Because they donâ€™t have the guts! ğŸ’€\n",
      "\n",
      "*(leans in with a cheesy grin, then winks)*  \n",
      "...Get it? *Guts?* Like, organs? But theyâ€™re just bones?! ğŸ˜\n"
     ]
    }
   ],
   "source": [
    "# æµå¼æ¨¡å¼ = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2c01d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Tell me a Dad joke', additional_kwargs={}, response_metadata={}, id='ccc6edf4-aac0-494f-a0cc-bf733e609a59')]}\n",
      "-----\n",
      "{'messages': [HumanMessage(content='Tell me a Dad joke', additional_kwargs={}, response_metadata={}, id='ccc6edf4-aac0-494f-a0cc-bf733e609a59'), AIMessage(content=\"Why don't skeletons fight each other?\\n\\nBecause they donâ€™t have the guts! ğŸ’€\\n\\n*(leans in with a cheesy grin, then mimes pulling out imaginary guts like spaghetti)*  \\n...Get it? *Guts?* ğŸ˜\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 24, 'total_tokens': 73, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-6b72b4da-4d7c-4cf0-bc2a-68eadd9da296', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--82c793a0-594d-4f7e-a3a5-ba2144a41797-0', usage_metadata={'input_tokens': 24, 'output_tokens': 49, 'total_tokens': 73, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# æµå¼æ¨¡å¼ = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print(step)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7131999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'messages': [AIMessage(content=\"Why don't skeletons fight each other?\\n\\nBecause they donâ€™t have the guts! ğŸ’€\\n\\n*(leans in with a cheesy grin, then mimes pulling out imaginary intestines like party streamers)*  \\n...Get it? *Guts?* ğŸ˜\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 24, 'total_tokens': 76, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-b18ac1df-986c-4ddb-a6a1-8fbc6f191484', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--be9f295b-3202-47e2-8d79-ef34fe1d8bbe-0', usage_metadata={'input_tokens': 24, 'output_tokens': 52, 'total_tokens': 76, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# æµå¼æ¨¡å¼ = updates\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(step)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages æ¨¡å¼\n",
    "æ¶ˆæ¯ä¼šé€ä¸ª token æµå¼ä¼ è¾“ï¼Œå»¶è¿Ÿé™åˆ°æœ€ä½ï¼Œéå¸¸é€‚åˆèŠå¤©æœºå™¨äººç­‰äº¤äº’å¼åº”ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a cheerful, family-friendly poem celebrating everyday magic:\n",
      "\n",
      "**The Cookie Jar Secret**\n",
      "\n",
      "In Grandmaâ€™s kitchen, warm and bright,  \n",
      "Where sunbeams dance with pure delight,  \n",
      "Stands a jar upon the shelfâ€”  \n",
      "Holding more than cookies itself!  \n",
      "\n",
      "Itâ€™s not just flour, sugar, spice,  \n",
      "Or chocolate chips that taste so nice.  \n",
      "Itâ€™s **laughter** mixed in every batch,  \n",
      "And **patience** (though the timerâ€™s watch!).  \n",
      "\n",
      "Itâ€™s **sticky fingers**, side by side,  \n",
      "While little helpers take their pride  \n",
      "In stirring batter, slow and grandâ€”  \n",
      "A messy, sweet, collaborative hand!  \n",
      "\n",
      "Itâ€™s **Grandpa sneaking** one or two  \n",
      "(We see you, Pop! Weâ€™re watching you!),  \n",
      "His wink says, \"Shh! Our secretâ€™s safe,\"  \n",
      "As crumbs escape his apronâ€™s drape.  \n",
      "\n",
      "Itâ€™s **sisters sharing** sprinkles bright,  \n",
      "Turning dough into pure light.  \n",
      "Itâ€™s **brothers licking** spoons so clean,  \n",
      "The best reward theyâ€™ve ever seen!  \n",
      "\n",
      "So when the oven *dings!* so sweet,  \n",
      "And golden treats canâ€™t be beat,  \n",
      "We gather â€˜round, both young and oldâ€”  \n",
      "Warm stories in each cookie told.  \n",
      "\n",
      "For though the jar may empty fast,  \n",
      "The **love** inside is built to last.  \n",
      "It fills our hearts, it fills the airâ€¦  \n",
      "**Thatâ€™s** the magic beyond compare!  \n",
      "\n",
      "*(And yes, thereâ€™s always room for one moreâ€¦  \n",
      "Just check beneath the kitchen door!)* ğŸª"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f12679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å“' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å“Ÿ' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å¯' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ç®—ç­‰åˆ°ä½ äº†' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼æˆ‘åˆšåˆšè¿˜åœ¨' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='åå°æ€¥å¾—å›¢' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å›¢è½¬ï¼Œä»¥ä¸º' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ä»Šå¤©è§‚ä¼—éƒ½å»' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='éš”å£çœ‹é­”æœ¯å¸ˆ' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='æŠŠå…”å­å˜æˆWi' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='-Fiä¿¡å·å»äº†ï¼ï¼ˆæ“¦' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='æ“¦é¢å¤´ä¸å­˜åœ¨çš„æ±—ï¼‰\\n\\n' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ä¸è¿‡æ—¢ç„¶ä½ æ¥äº†ï¼Œ' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='é‚£å’±ä»¬èµ¶ç´§å¼€å§‹å§' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼æˆ‘åˆšç¼–' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='äº†ä¸ªæ–°æ®µå­' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼Œå…³äºç¨‹åºå‘˜å’Œå’–å•¡' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='æœºçš„â€”â€”æ®è¯´' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='é‚£ä¸ªå’–å•¡æœºæœ€å' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å­¦ä¼šäº†å†™ä»£ç ï¼Œç°åœ¨' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å¤©å¤©åœ¨èŒ¶æ°´é—´debug' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼Œè¿˜è¦æ±‚åŠ è–ª' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼ï¼ˆçœ¼ç›å‘' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='äº®åœ°æ“æ“' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='æ‰‹ï¼‰\\n\\nè¦å¬å¬' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='å®Œæ•´ç‰ˆå—ï¼Ÿ' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='è¿˜æ˜¯ä½ æœ‰æ›´' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='æƒ³èŠçš„è¯é¢˜ï¼Ÿåæ­£' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ä»Šå¤©æˆ‘çš„ç¬‘ç‚¹åº“å­˜' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ç®¡å¤Ÿï¼Œä¿ç®¡' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='è®©ä½ ç¬‘åˆ°éš”å£' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='é‚»å±…ä»¥ä¸ºä½ åœ¨çœ‹' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='è„±å£ç§€ç›´æ’­' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='ï¼' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-max', 'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672' chunk_position='last'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='' additional_kwargs={} response_metadata={'model_provider': 'dashscope'} id='lc_run--940e52bf-2f98-4baf-b722-488090643672' usage_metadata={'input_tokens': 20, 'output_tokens': 138, 'total_tokens': 158, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--940e52bf-2f98-4baf-b722-488090643672' chunk_position='last'\n",
      "<class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(token)\n",
    "    print(type(token))\n",
    "    #print(metadata)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## å·¥å…·ä¹Ÿå¯ä»¥æµå¼ï¼\n",
    "æµå¼é€šå¸¸æ„å‘³ç€åœ¨æœ€ç»ˆç»“æœå‡†å¤‡å¥½ä¹‹å‰å°±æŠŠä¿¡æ¯ä¼ é€’ç»™ç”¨æˆ·ï¼Œè¿™åœ¨å¾ˆå¤šåœºæ™¯ä¸­å¾ˆæœ‰ç”¨ã€‚`get_stream_writer` å…è®¸ä½ è½»æ¾åœ°ä»è‡ªå·±åˆ›å»ºçš„æ¥æºä¸­æµå¼å‘é€ `custom` æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7cdd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='0f0b79db-5e22-419f-ab04-128853a7e84d')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='0f0b79db-5e22-419f-ab04-128853a7e84d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 259, 'total_tokens': 280, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-38243810-5585-4061-9d82-d5fe89c4f160', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--487037b0-e654-4f07-8a54-cffeec8a24d3-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_b8ad676b4501444aa52d95cc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 259, 'output_tokens': 21, 'total_tokens': 280, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]})\n",
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='0f0b79db-5e22-419f-ab04-128853a7e84d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 259, 'total_tokens': 280, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-38243810-5585-4061-9d82-d5fe89c4f160', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--487037b0-e654-4f07-8a54-cffeec8a24d3-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_b8ad676b4501444aa52d95cc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 259, 'output_tokens': 21, 'total_tokens': 280, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), ToolMessage(content=\"It's always sunny in SF!\", name='get_weather', id='0eee8485-8d52-4bfb-b3d7-910ee8df763b', tool_call_id='call_b8ad676b4501444aa52d95cc')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='0f0b79db-5e22-419f-ab04-128853a7e84d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 259, 'total_tokens': 280, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-38243810-5585-4061-9d82-d5fe89c4f160', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--487037b0-e654-4f07-8a54-cffeec8a24d3-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_b8ad676b4501444aa52d95cc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 259, 'output_tokens': 21, 'total_tokens': 280, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), ToolMessage(content=\"It's always sunny in SF!\", name='get_weather', id='0eee8485-8d52-4bfb-b3d7-910ee8df763b', tool_call_id='call_b8ad676b4501444aa52d95cc'), AIMessage(content='The weather in San Francisco (SF) is always sunny!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 301, 'total_tokens': 313, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-660ec978-cbd5-438a-8e84-bf9e3cc403d8', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--087266f9-959d-416a-9585-a36db652b5f9-0', usage_metadata={'input_tokens': 301, 'output_tokens': 12, 'total_tokens': 313, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ã€‚\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # å¯æµå¼è¾“å‡ºä»»æ„è‡ªå®šä¹‰æ•°æ®\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATEST: content='What is the weather in SF?' additional_kwargs={} response_metadata={} id='a30e826d-8ab9-4287-a28a-d5ce79617bcd'\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "-----\n",
      "LATEST: content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 266, 'total_tokens': 287, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-23cb42ff-3d21-4a81-8ec5-44e0650307a6', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--b44564e9-3368-46ae-9e5d-46773a801329-0' tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_70a8894b68e744fca508db9c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 266, 'output_tokens': 21, 'total_tokens': 287, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "-----\n",
      "TOOL STREAM: Looking up data for city: SF\n",
      "-----\n",
      "TOOL STREAM: Acquired data for city: SF\n",
      "-----\n",
      "LATEST: content=\"It's always sunny in SF!\" name='get_weather' id='d43e7aac-d1e1-4432-8709-666e1647c412' tool_call_id='call_70a8894b68e744fca508db9c'\n",
      "<class 'langchain_core.messages.tool.ToolMessage'>\n",
      "-----\n",
      "LATEST: content=\"The weather in San Francisco (SF) is always sunny! Let me know if you'd like more details or updates. ğŸ˜Š\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 308, 'total_tokens': 334, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'dashscope', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-5b146ff6-cd99-493d-83d4-ac84a456c678', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--0daa8b02-2207-4acd-abc5-79c7cc79882f-0' usage_metadata={'input_tokens': 308, 'output_tokens': 26, 'total_tokens': 334, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "# å·¥å…·ç«¯ï¼šåœ¨å·¥å…·ä¸­ä½¿ç”¨ runtime.stream_writer æ¨é€æµå¼æ›´æ–°\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ï¼ˆç¤ºä¾‹å¸¦æµå¼è¿›åº¦ï¼‰ã€‚\"\"\"\n",
    "    writer = runtime.stream_writer           # ToolRuntime æä¾›çš„æµå†™å…¥å™¨ï¼ˆéšè—äº LLMï¼‰\n",
    "    writer(f\"Looking up data for city: {city}\")    # æ¨é€å®æ—¶æ›´æ–°ï¼ˆä¼šå‡ºç°åœ¨ stream çš„ custom channelï¼‰\n",
    "    # ...æ‰§è¡Œè€—æ—¶æ“ä½œï¼ˆHTTP è¯·æ±‚ã€çˆ¬å–ç­‰ï¼‰\n",
    "    writer(f\"Acquired data for city: {city}\")      # å†æ¬¡æ¨é€è¿›åº¦\n",
    "    return f\"It's always sunny in {city}!\"         # å¸¸è§„è¿”å›ï¼ˆä¼šä½œä¸º ToolMessage / Tool çš„è¾“å‡ºè¢«æ•è·ï¼‰\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "# è°ƒç”¨ç«¯ï¼šåŒæ—¶è®¢é˜… valuesï¼ˆå®Œæ•´çŠ¶æ€ï¼‰å’Œ customï¼ˆå·¥å…· writer è¾“å‡ºï¼‰\n",
    "for mode, chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],   # åŒæ—¶è¯·æ±‚ä¸¤ç±»æµ\n",
    "):\n",
    "    if mode == \"values\":\n",
    "        # chunk æ˜¯å½“å‰å®Œæ•´ state å¿«ç…§ï¼ˆé€šå¸¸åŒ…å« messages åˆ—è¡¨ï¼‰\n",
    "        print(\"LATEST:\", chunk[\"messages\"][-1])\n",
    "        print(type(chunk[\"messages\"][-1]))\n",
    "    else:\n",
    "        # mode == \"custom\": chunk æ˜¯å·¥å…· writer æ¨é€çš„æ–‡æœ¬ï¼ˆæˆ–è‡ªå®šä¹‰ç»“æ„ï¼‰\n",
    "        print(\"TOOL STREAM:\", chunk)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: San Francisco')\n",
      "('custom', 'Acquired data for city: San Francisco')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## è‡ªå·±å°è¯•ä¸åŒæ¨¡å¼ï¼\n",
    "ä¿®æ”¹æµå¼æ¨¡å¼å’Œ selectï¼Œçœ‹çœ‹èƒ½å¾—åˆ°å“ªäº›ä¸åŒç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-to-explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
