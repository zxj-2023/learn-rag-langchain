{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# 使用LangChain和RAGAS对RAG系统进行自动有效评估\n",
        "\n",
        "我们主要讨论一下LLM RAG问答系统中一个重要的组成部分:\n",
        "\n",
        "- Evaluation\n",
        "\n",
        "我们主要使用LangChain 构建RAG问答系统，利用 RAGAS 框架进行评估，因为它正逐渐成为评估 RAG 系统的标准方法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 首先安装 依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5BN13TZlSCv4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U -q langchain openai ragas arxiv pymupdf chromadb wandb tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "c33f7eee-b819-40bd-dc75-ce90721a6a94"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "### 数据准备\n",
        "\n",
        "主要以Arxiv的论文为例进行评估，通过 `ArxivLoader` 加载数据(论文)作为RAG的上下文。\n",
        "\n",
        "- [`ArxivLoader`](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html#langchain_community.document_loaders.arxiv.ArxivLoader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTDNFXaBSO2j",
        "outputId": "3b24521d-5c6f-466b-d818-46ce68d359ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import ArxivLoader\n",
        "#ArxivLoader 是 LangChain 库中的一个文档加载器，用于从 ArXiv 网站加载论文。\n",
        "paper_docs = ArxivLoader(query=\"2309.15217\", load_max_docs=1).load()\n",
        "len(paper_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNPAWPgNSyGP",
        "outputId": "b2f80fc8-792c-489a-b8d4-9f98678c679a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Published': '2025-04-28', 'Title': 'Ragas: Automated Evaluation of Retrieval Augmented Generation', 'Authors': 'Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert', 'Summary': 'We introduce Ragas (Retrieval Augmented Generation Assessment), a framework\\nfor reference-free evaluation of Retrieval Augmented Generation (RAG)\\npipelines. RAG systems are composed of a retrieval and an LLM based generation\\nmodule, and provide LLMs with knowledge from a reference textual database,\\nwhich enables them to act as a natural language layer between a user and\\ntextual databases, reducing the risk of hallucinations. Evaluating RAG\\narchitectures is, however, challenging because there are several dimensions to\\nconsider: the ability of the retrieval system to identify relevant and focused\\ncontext passages, the ability of the LLM to exploit such passages in a faithful\\nway, or the quality of the generation itself. With Ragas, we put forward a\\nsuite of metrics which can be used to evaluate these different dimensions\\n\\\\textit{without having to rely on ground truth human annotations}. We posit\\nthat such a framework can crucially contribute to faster evaluation cycles of\\nRAG architectures, which is especially important given the fast adoption of\\nLLMs.'}\n"
          ]
        }
      ],
      "source": [
        "for doc in paper_docs:\n",
        "  print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "### 创建RAG文本分割、Embedding model 、 向量库存储\n",
        "\n",
        "我们主要使用 `RecursiveCharacterTextSplitter` 切割文本，通过`OpenAIEmbeddings()`进行文本编码，存储到 `VectorStore`。\n",
        "\n",
        "- `RecursiveCharacterTextSplitter()`\n",
        "- `OpenAIEmbeddings()`\n",
        "- `Chroma`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import DashScopeEmbeddings\n",
        "embeddings_model = DashScopeEmbeddings(\n",
        "        model=\"text-embedding-v2\",\n",
        "        dashscope_api_key=openai.api_key,\n",
        "    )\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
        "\n",
        "docs = text_splitter.split_documents(paper_docs)\n",
        "\n",
        "vectorstore = Chroma.from_documents(docs, embeddings_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chroma 向量数据库默认情况下是内存存储，这意味着数据在程序运行结束后不会保留。\n",
        "但是，Chroma 也支持持久化存储，您可以指定一个路径将数据保存到磁盘上。这样，即使程序关闭，数据也会被保留，并在下次启动时自动加载。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnRzYx4c_2mZ",
        "outputId": "59d9bdd8-0414-4e8b-c285-bf3a2760e26a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUh8EVI_6TZ",
        "outputId": "643fca9d-77c0-4296-d953-ec62d6de8954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "497\n"
          ]
        }
      ],
      "source": [
        "print(max([len(chunk.page_content) for chunk in docs]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9kNIUUTxdT"
      },
      "source": [
        "现在我们可以利用 `Chroma` 向量库的 `.as_retriever()` 方式进行检索，需要控制的主要参数为 `k`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bwbdftltT29h"
      },
      "outputs": [],
      "source": [
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ectorstore.as_retriever() : 这个方法的作用是将一个向量数据库实例（ vectorstore ）转换为 LangChain 中的一个检索器（ Retriever ）对象。检索器是 LangChain 中负责根据用户查询从数据源中获取相关文档的核心组件。\n",
        "- \"k\" : 这个键表示要检索的“最相似”文档的数量。在这里， \"k\" : 3 意味着当检索器接收到一个查询时，它将从向量存储中返回与该查询最相似的 3 个文档。这在 RAG（检索增强生成）系统中非常常见，用于限制传递给大型语言模型的上下文信息量，以提高效率和相关性。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "检索器的作用\n",
        "检索器（Retriever）是一个核心组件，其主要作用是从一个数据源（如向量数据库、文档加载器等）中根据给定的查询（query）检索出相关的文档或信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r0Pie4xqUCkW"
      },
      "outputs": [],
      "source": [
        "relevant_docs = base_retriever.invoke(\"What is Retrieval Augmented Generation?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CiHTD0UKj7",
        "outputId": "fab040cf-971f-440a-a6aa-93873c8e152f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 创建prompt ——— 生成答案\n",
        "我们需要利用`LLM`对`Context` 生成一系列的问题的`answer`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['context', 'question'] input_types={} partial_variables={} template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\"\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"You are an assistant for question-answering tasks. \n",
        "Use the following pieces of retrieved context to answer the question. \n",
        "If you don't know the answer, just say that you don't know. \n",
        "\n",
        "Question: {question} \n",
        "\n",
        "Context: {context} \n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template, \n",
        "    input_variables=[\"context\",\"question\"]\n",
        "  )\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 生成`answer`,利用LLM\n",
        "利用 `Runnable` 定义一个 `chain` 实现rag全流程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"qwen-plus-2025-04-28\", \n",
        "    temperature=0,\n",
        "    api_key=\"sk-ba2dda3817f145d7af141fdf32e31d90\",\n",
        "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
        "    )\n",
        "#RunnablePassthrough将输入数据原封不动地传递到输出\n",
        "#StrOutputParser() 它被用作 RAG 链的最后一步，确保最终的答案以字符串形式输出。\n",
        "rag_chain = (\n",
        "    {\"context\": base_retriever,  \"question\": RunnablePassthrough()} \n",
        "    | prompt \n",
        "    | llm\n",
        "    | StrOutputParser() \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='我是通义千问，由通义实验室自主研发的超大规模语言模型。我能够回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。我在多国语言上都有很好的掌握，能为你提供多样化的帮助。如果你有任何问题或需要帮助，欢迎随时告诉我！' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 15, 'total_tokens': 94, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen-plus-2025-04-28', 'system_fingerprint': None, 'id': 'chatcmpl-e98b6bd5-1878-93c9-9019-e4722ccee050', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--89d164d0-9d47-4335-a799-980889ef14ee-0' usage_metadata={'input_tokens': 15, 'output_tokens': 79, 'total_tokens': 94, 'input_token_details': {}, 'output_token_details': {}}\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(\"你是什么模型\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 创建 RAGAs 所需的数据\n",
        "question  Answer   contexts  ground_truths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/miniconda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/tmp/ipykernel_121195/3288309814.py:26: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])\n"
          ]
        }
      ],
      "source": [
        "# Ragas 数据集格式要求  ['question', 'answer', 'contexts', 'ground_truths']\n",
        "'''\n",
        "{\n",
        "    \"question\": [], <-- 问题基于Context的\n",
        "    \"answer\": [], <-- 答案基于LLM生成的\n",
        "    \"contexts\": [], <-- context\n",
        "    \"ground_truths\": [] <-- 标准答案\n",
        "}\n",
        "'''\n",
        "\n",
        "from datasets import Dataset\n",
        "#构建问题与标准答案（黄金数据集）\n",
        "questions = [\"What is faithfulness ?\", \n",
        "             \"How many pages are included in the WikiEval dataset, and which years do they cover information from?\",\n",
        "             \"Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?\",\n",
        "            ]\n",
        "ground_truths = [\"Faithfulness refers to the idea that the answer should be grounded in the given context.\",\n",
        "                  \" To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.\",\n",
        "                \"Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.\"]              \n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "# 生成答案\n",
        "for query in questions:\n",
        "    answers.append(rag_chain.invoke(query))\n",
        "    contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])\n",
        "\n",
        "# 构建数据\n",
        "data = {\n",
        "    \"question\": questions,\n",
        "    \"answer\": answers,\n",
        "    \"contexts\": contexts,\n",
        "    \"reference\": ground_truths\n",
        "}\n",
        "dataset = Dataset.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'reference'],\n",
              "    num_rows: 3\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 使用RAGAs 进行评估"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ragas 数据集格式要求  ['question', 'answer', 'contexts', 'ground_truths']\n",
        "'''\n",
        "{\n",
        "    \"question\": [], <-- 问题基于Context的\n",
        "    \"answer\": [], <-- 答案基于LLM生成的\n",
        "    \"contexts\": [], <-- context\n",
        "    \"ground_truths\": [] <-- 标准答案\n",
        "}\n",
        "'''\n",
        "\n",
        "from datasets import Dataset\n",
        "#构建问题与标准答案（黄金数据集）\n",
        "questions = [\"What is faithfulness ?\", \n",
        "             \"How many pages are included in the WikiEval dataset, and which years do they cover information from?\",\n",
        "             \"Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?\",\n",
        "            ]\n",
        "ground_truths = [\"Faithfulness refers to the idea that the answer should be grounded in the given context.\",\n",
        "                  \" To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.\",\n",
        "                \"Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.\"]              \n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "# 生成答案\n",
        "for query in questions:\n",
        "    answers.append(rag_chain.invoke(query))\n",
        "    contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])\n",
        "\n",
        "# 构建数据\n",
        "data = {\n",
        "    \"user_input\": questions,\n",
        "    \"response\": answers,\n",
        "    \"retrieved_contexts\": contexts,\n",
        "    \"reference\": ground_truths\n",
        "}\n",
        "dataset = Dataset.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#将评估数据转换成 Ragas 框架专用的格式 。\n",
        "from ragas import EvaluationDataset\n",
        "evaluation_dataset = EvaluationDataset.from_list(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'response', 'reference'], len=3)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以使用一组常用的RAG评估指标，在收集的数据集上评估我们的RAG系统。您可以选择任何模型作为评估用LLM来进行评估。\n",
        "ragas默认使用openai的api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 9/9 [01:05<00:00,  7.26s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 1.0000, 'faithfulness': 0.8333, 'factual_correctness(mode=f1)': 0.8733}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
        "from ragas import evaluate\n",
        "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:  50%|█████     | 6/12 [00:23<00:17,  2.85s/it]Exception raised in Job[11]: AuthenticationError(Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-ba2dd***********************1d90. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}})\n",
            "Evaluating:  67%|██████▋   | 8/12 [00:31<00:13,  3.26s/it]Exception raised in Job[3]: AuthenticationError(Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-ba2dd***********************1d90. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}})\n",
            "Evaluating:  75%|███████▌  | 9/12 [00:32<00:08,  2.68s/it]Exception raised in Job[7]: AuthenticationError(Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-ba2dd***********************1d90. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}})\n",
            "Evaluating: 100%|██████████| 12/12 [00:40<00:00,  3.37s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 1.0000, 'context_recall': 1.0000, 'faithfulness': 0.8571, 'answer_relevancy': nan}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision\n",
        ")\n",
        "\n",
        "\n",
        "result = evaluate(\n",
        "    dataset = dataset, \n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "        faithfulness,\n",
        "        answer_relevancy\n",
        "    ],\n",
        "    llm=evaluator_llm\n",
        ")\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness(mode=f1)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is faithfulness ?</td>\n",
              "      <td>[First, Faithfulness refers to the idea that the an-\\nswer should be grounded in the given context. This\\nis important to avoid hallucinations, and to ensure\\nthat the retrieved context can act as a justification\\nfor the generated answer. Indeed, RAG systems are\\noften used in applications where the factual con-\\nsistency of the generated text w.r.t. the grounded\\nsources is highly important, e.g. in domains such as\\nlaw, where information is constantly evolving. Sec-, Faithfulness measures the information\\nconsistency of the answer against the\\ngiven context. Any claims that are made\\nin the answer that cannot be deduced\\nfrom context should be penalized.\\nGiven an answer and context, assign a\\nscore for faithfulness in the range 0-10.\\ncontext: [context]\\nanswer: [answer]\\nTies, where the same score is assigned by the LLM\\nto both answer candidates, were broken randomly.\\nThe second baseline, shown as GPT Ranking, in-, considered quality dimensions. For faithfulness\\nand context relevance, the two annotators agreed in\\naround 95% of cases. For answer relevance, they\\nagreed in around 90% of the cases. Disagreements\\nwere resolved after a discussion between the anno-\\ntators.\\nFaithfulness\\nTo obtain human judgements about\\nfaithfulness, we first used ChatGPT to answer the\\nquestion without access to any additional context.\\nWe then asked the annotators to judge which of the]</td>\n",
              "      <td>Faithfulness, in the context of Retrieval Augmented Generation (RAG) systems, refers to the degree to which the generated answer is grounded in and consistent with the provided context. It ensures that the claims made in the answer can be logically deduced from the given context, thereby avoiding hallucinations or unsupported statements. Faithfulness is critical in applications where factual accuracy and consistency with reference sources are essential, such as legal or medical domains.</td>\n",
              "      <td>Faithfulness refers to the idea that the answer should be grounded in the given context.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How many pages are included in the WikiEval dataset, and which years do they cover information from?</td>\n",
              "      <td>[which we refer to as WikiEval4. To construct the\\ndataset, we first selected 50 Wikipedia pages cov-\\nering events that have happened since the start of\\n20225. In selecting these pages, we prioritised\\nthose with recent edits. For each of the 50 pages,\\nwe then asked ChatGPT to suggest a question that\\ncan be answered based on the introductory section\\nof the page, using the following prompt:\\nYour task is to formulate a question from\\ngiven context satisfying the rules given\\nbelow:, which are annotated with human judgments. We\\ncan then verify to what extent our metrics agree\\nwith human assessments of faithfulness, answer\\nrelevance and context relevance. Since we are not\\naware of any publicly available datasets that could\\nbe used for this purpose, we created a new dataset,\\nwhich we refer to as WikiEval4. To construct the\\ndataset, we first selected 50 Wikipedia pages cov-\\nering events that have happened since the start of\\n20225. In selecting these pages, we prioritised, tems with valuable insights, even in the absence\\nof any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from Ragas are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.\\nReferences\\nAmos Azaria and Tom M. Mitchell. 2023. The inter-\\nnal state of an LLM knows when its lying. CoRR,\\nabs/2304.13734.\\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\\nTrevor Cai, Eliza Rutherford, Katie Millican, George]</td>\n",
              "      <td>The WikiEval dataset includes 50 Wikipedia pages, and the information covered in these pages pertains to events that have happened since the start of 2022.</td>\n",
              "      <td>To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?</td>\n",
              "      <td>[Abstract\\nWe introduce Ragas (Retrieval Augmented\\nGeneration Assessment), a framework for\\nreference-free evaluation of Retrieval Aug-\\nmented Generation (RAG) pipelines.\\nRAG\\nsystems are composed of a retrieval and an\\nLLM based generation module, and provide\\nLLMs with knowledge from a reference textual\\ndatabase, which enables them to act as a natu-\\nral language layer between a user and textual\\ndatabases, reducing the risk of hallucinations.\\nEvaluating RAG architectures is, however, chal-, Ragas: Automated Evaluation of Retrieval Augmented Generation\\nShahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗\\n†Exploding Gradients\\n∗CardiffNLP, Cardiff University, United Kingdom\\n♢AMPLYFI, United Kingdom\\nshahules786@gmail.com,jamesjithin97@gmail.com\\n{espinosa-ankel,schockaerts1}@cardiff.ac.uk\\nAbstract\\nWe introduce Ragas (Retrieval Augmented\\nGeneration Assessment), a framework for\\nreference-free evaluation of Retrieval Aug-\\nmented Generation (RAG) pipelines.\\nRAG, retrieval-augmented systems is thus paramount. In\\npractice, RAG systems are often evaluated in terms\\nof the language modelling task itself, i.e. by mea-\\nsuring perplexity on some reference corpus. How-\\never, such evaluations are not always predictive\\nof downstream performance (Wang et al., 2023c).\\nMoreover, this evaluation strategy relies on the LM\\nprobabilities, which are not accessible for some\\nclosed models (e.g. ChatGPT and GPT-4). Ques-\\ntion answering is another common evaluation task,]</td>\n",
              "      <td>Evaluating Retrieval Augmented Generation (RAG) systems is challenging because there are multiple dimensions that need to be assessed. These include:\\n\\n1. **Retrieval Effectiveness**: The ability of the retrieval system to identify relevant and focused context passages from the reference textual database.\\n2. **Faithful Exploitation by LLMs**: The ability of the large language model (LLM) to effectively and faithfully use the retrieved passages when generating responses.\\n3. **Generation Quality**: The quality, coherence, and relevance of the final generated output.\\n\\nTraditional evaluation methods, such as measuring perplexity or relying on question-answering tasks, may not always predict downstream performance or may not be feasible for closed models. Additionally, evaluations often rely on ground truth human annotations, which can be time-consuming and expensive. This complexity necessitates a more robust and automated evaluation framework like Ragas, which can assess these different dimensions without requiring human annotations.</td>\n",
              "      <td>Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                             user_input  \\\n",
              "0                                                                                What is faithfulness ?   \n",
              "1  How many pages are included in the WikiEval dataset, and which years do they cover information from?   \n",
              "2                           Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     retrieved_contexts  \\\n",
              "0                                                                                                              [First, Faithfulness refers to the idea that the an-\\nswer should be grounded in the given context. This\\nis important to avoid hallucinations, and to ensure\\nthat the retrieved context can act as a justification\\nfor the generated answer. Indeed, RAG systems are\\noften used in applications where the factual con-\\nsistency of the generated text w.r.t. the grounded\\nsources is highly important, e.g. in domains such as\\nlaw, where information is constantly evolving. Sec-, Faithfulness measures the information\\nconsistency of the answer against the\\ngiven context. Any claims that are made\\nin the answer that cannot be deduced\\nfrom context should be penalized.\\nGiven an answer and context, assign a\\nscore for faithfulness in the range 0-10.\\ncontext: [context]\\nanswer: [answer]\\nTies, where the same score is assigned by the LLM\\nto both answer candidates, were broken randomly.\\nThe second baseline, shown as GPT Ranking, in-, considered quality dimensions. For faithfulness\\nand context relevance, the two annotators agreed in\\naround 95% of cases. For answer relevance, they\\nagreed in around 90% of the cases. Disagreements\\nwere resolved after a discussion between the anno-\\ntators.\\nFaithfulness\\nTo obtain human judgements about\\nfaithfulness, we first used ChatGPT to answer the\\nquestion without access to any additional context.\\nWe then asked the annotators to judge which of the]   \n",
              "1                                         [which we refer to as WikiEval4. To construct the\\ndataset, we first selected 50 Wikipedia pages cov-\\nering events that have happened since the start of\\n20225. In selecting these pages, we prioritised\\nthose with recent edits. For each of the 50 pages,\\nwe then asked ChatGPT to suggest a question that\\ncan be answered based on the introductory section\\nof the page, using the following prompt:\\nYour task is to formulate a question from\\ngiven context satisfying the rules given\\nbelow:, which are annotated with human judgments. We\\ncan then verify to what extent our metrics agree\\nwith human assessments of faithfulness, answer\\nrelevance and context relevance. Since we are not\\naware of any publicly available datasets that could\\nbe used for this purpose, we created a new dataset,\\nwhich we refer to as WikiEval4. To construct the\\ndataset, we first selected 50 Wikipedia pages cov-\\nering events that have happened since the start of\\n20225. In selecting these pages, we prioritised, tems with valuable insights, even in the absence\\nof any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from Ragas are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.\\nReferences\\nAmos Azaria and Tom M. Mitchell. 2023. The inter-\\nnal state of an LLM knows when its lying. CoRR,\\nabs/2304.13734.\\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\\nTrevor Cai, Eliza Rutherford, Katie Millican, George]   \n",
              "2  [Abstract\\nWe introduce Ragas (Retrieval Augmented\\nGeneration Assessment), a framework for\\nreference-free evaluation of Retrieval Aug-\\nmented Generation (RAG) pipelines.\\nRAG\\nsystems are composed of a retrieval and an\\nLLM based generation module, and provide\\nLLMs with knowledge from a reference textual\\ndatabase, which enables them to act as a natu-\\nral language layer between a user and textual\\ndatabases, reducing the risk of hallucinations.\\nEvaluating RAG architectures is, however, chal-, Ragas: Automated Evaluation of Retrieval Augmented Generation\\nShahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗\\n†Exploding Gradients\\n∗CardiffNLP, Cardiff University, United Kingdom\\n♢AMPLYFI, United Kingdom\\nshahules786@gmail.com,jamesjithin97@gmail.com\\n{espinosa-ankel,schockaerts1}@cardiff.ac.uk\\nAbstract\\nWe introduce Ragas (Retrieval Augmented\\nGeneration Assessment), a framework for\\nreference-free evaluation of Retrieval Aug-\\nmented Generation (RAG) pipelines.\\nRAG, retrieval-augmented systems is thus paramount. In\\npractice, RAG systems are often evaluated in terms\\nof the language modelling task itself, i.e. by mea-\\nsuring perplexity on some reference corpus. How-\\never, such evaluations are not always predictive\\nof downstream performance (Wang et al., 2023c).\\nMoreover, this evaluation strategy relies on the LM\\nprobabilities, which are not accessible for some\\nclosed models (e.g. ChatGPT and GPT-4). Ques-\\ntion answering is another common evaluation task,]   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      response  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Faithfulness, in the context of Retrieval Augmented Generation (RAG) systems, refers to the degree to which the generated answer is grounded in and consistent with the provided context. It ensures that the claims made in the answer can be logically deduced from the given context, thereby avoiding hallucinations or unsupported statements. Faithfulness is critical in applications where factual accuracy and consistency with reference sources are essential, such as legal or medical domains.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The WikiEval dataset includes 50 Wikipedia pages, and the information covered in these pages pertains to events that have happened since the start of 2022.   \n",
              "2  Evaluating Retrieval Augmented Generation (RAG) systems is challenging because there are multiple dimensions that need to be assessed. These include:\\n\\n1. **Retrieval Effectiveness**: The ability of the retrieval system to identify relevant and focused context passages from the reference textual database.\\n2. **Faithful Exploitation by LLMs**: The ability of the large language model (LLM) to effectively and faithfully use the retrieved passages when generating responses.\\n3. **Generation Quality**: The quality, coherence, and relevance of the final generated output.\\n\\nTraditional evaluation methods, such as measuring perplexity or relying on question-answering tasks, may not always predict downstream performance or may not be feasible for closed models. Additionally, evaluations often rely on ground truth human annotations, which can be time-consuming and expensive. This complexity necessitates a more robust and automated evaluation framework like Ragas, which can assess these different dimensions without requiring human annotations.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                    reference  \\\n",
              "0                                                                                                                                                                                                                    Faithfulness refers to the idea that the answer should be grounded in the given context.   \n",
              "1                                                                                                                                                                                  To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.   \n",
              "2  Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.   \n",
              "\n",
              "   context_recall  faithfulness  factual_correctness(mode=f1)  \n",
              "0             1.0           1.0                          1.00  \n",
              "1             1.0           1.0                          1.00  \n",
              "2             1.0           0.5                          0.62  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "df = result.to_pandas()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fff4a6672c848a38945e19101c46168": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d17b8847ab34a1d8fc79430e8b64a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c8b5933c754a1192456f43682276c5",
            "placeholder": "​",
            "style": "IPY_MODEL_84abf77081a04bb686f794b49e04761d",
            "value": " 1/1 [00:00&lt;00:00, 35.79ba/s]"
          }
        },
        "207785da1f404d6ea0e8c63655a7aa51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fc25617c664e4aa02b7457832c1bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256a0dbb2f104d928e181d2a882a9867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2add9d30edd84152bb6d7bfa4ed2d910": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31390facfbeb455fa83067fc23d30718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5367cbe7ca4d43b089ff0d5d7cd17d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53ebcf672a244978391cae559db5bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_f2de6a2c1f4b4a2fa5196028c0da0754",
            "value": " 1/1 [00:00&lt;00:00, 18.79ba/s]"
          }
        },
        "56098a347ea94ea3b10bd8d2ec0d4288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567176b50d074a1c9d384a8df8c3ff4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34ffd11b98045b9bae326dd48a54896",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e19fc9963c4bf39293bda7c2030d5a",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "632135599e39470aac1a3bb3d3de0ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_567176b50d074a1c9d384a8df8c3ff4c",
              "IPY_MODEL_6bfa39f2c84e4f08b5ffb9a416398824",
              "IPY_MODEL_911b40169865413b98643789150e5495"
            ],
            "layout": "IPY_MODEL_2add9d30edd84152bb6d7bfa4ed2d910"
          }
        },
        "65f75f3d72cd415faffb32999893738d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fff4a6672c848a38945e19101c46168",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de662cb67d054f08a15d191923d40369",
            "value": 1
          }
        },
        "68790cfe4ea14fc4a63275f3e99c468f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfa39f2c84e4f08b5ffb9a416398824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15c27b0523a429e9d77f439d47ada90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_256a0dbb2f104d928e181d2a882a9867",
            "value": 1
          }
        },
        "6e7fb9a1d1454fcd9bcf5b5f748fb975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71237d176b2c4138a5e0346d10482257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761e3c6035bf49429b3035145451d2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207785da1f404d6ea0e8c63655a7aa51",
            "placeholder": "​",
            "style": "IPY_MODEL_71237d176b2c4138a5e0346d10482257",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "7940d9e3f5fa4592b58dec3fdb55595a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84abf77081a04bb686f794b49e04761d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86761a36bdb04fed9f1dae6e74da54ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e079c0eb3d9c4ae3a40491f059a864f7",
              "IPY_MODEL_d4bde97f3895450782030cad7808ea59",
              "IPY_MODEL_1d17b8847ab34a1d8fc79430e8b64a12"
            ],
            "layout": "IPY_MODEL_fb953d8d116e4cc389dbc23a0055873f"
          }
        },
        "911b40169865413b98643789150e5495": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68790cfe4ea14fc4a63275f3e99c468f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7df092ac205443e8baa3646ff1eae5b",
            "value": " 1/1 [00:00&lt;00:00, 33.41ba/s]"
          }
        },
        "95d92c5c74e845779337eb727c2bbfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56098a347ea94ea3b10bd8d2ec0d4288",
            "placeholder": "​",
            "style": "IPY_MODEL_7940d9e3f5fa4592b58dec3fdb55595a",
            "value": " 1/1 [00:00&lt;00:00, 33.86ba/s]"
          }
        },
        "b4a71cf676584200b46922fb976d1d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fc25617c664e4aa02b7457832c1bef",
            "placeholder": "​",
            "style": "IPY_MODEL_b556054df18d47aa8cb58ac482ca31bb",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "b53ebcf672a244978391cae559db5bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b556054df18d47aa8cb58ac482ca31bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf27f78edb15477492fb2d5dd8dc5137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7f045bdbe24360ad2aa2f4c8f02e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_761e3c6035bf49429b3035145451d2df",
              "IPY_MODEL_ffb7c97e7af648aaa13a43427154140e",
              "IPY_MODEL_95d92c5c74e845779337eb727c2bbfc0"
            ],
            "layout": "IPY_MODEL_6e7fb9a1d1454fcd9bcf5b5f748fb975"
          }
        },
        "c077837b8b044c2fb14dcd8fbc44a37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15c27b0523a429e9d77f439d47ada90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4bc64d47f2e4a239cf7156e7812887d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a71cf676584200b46922fb976d1d50",
              "IPY_MODEL_65f75f3d72cd415faffb32999893738d",
              "IPY_MODEL_5367cbe7ca4d43b089ff0d5d7cd17d3c"
            ],
            "layout": "IPY_MODEL_31390facfbeb455fa83067fc23d30718"
          }
        },
        "c9f479f81119450bb451d5830361467c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4bde97f3895450782030cad7808ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e556e254882340168833ecf1a7153a90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c077837b8b044c2fb14dcd8fbc44a37b",
            "value": 1
          }
        },
        "de662cb67d054f08a15d191923d40369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e079c0eb3d9c4ae3a40491f059a864f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf27f78edb15477492fb2d5dd8dc5137",
            "placeholder": "​",
            "style": "IPY_MODEL_ee96a569b8a54944bcac1b1bc164e53e",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "e3e19fc9963c4bf39293bda7c2030d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e556e254882340168833ecf1a7153a90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c8b5933c754a1192456f43682276c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7df092ac205443e8baa3646ff1eae5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed457547dc154f6bbce4ec970bb09c76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee96a569b8a54944bcac1b1bc164e53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2de6a2c1f4b4a2fa5196028c0da0754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f34ffd11b98045b9bae326dd48a54896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb953d8d116e4cc389dbc23a0055873f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb7c97e7af648aaa13a43427154140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed457547dc154f6bbce4ec970bb09c76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9f479f81119450bb451d5830361467c",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
