{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c9e547f",
      "metadata": {},
      "source": [
        "[PROTECTED$11$](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [PROTECTED$12$](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
      "metadata": {},
      "source": [
        "# æµå¼ä¼ è¾“ï¼ˆStreamingï¼‰\n",
        "\n",
        "## è¯„è®ºï¼ˆReviewï¼‰\n",
        "\n",
        "In module 2, covered a few ways to customize graph state and memory.\n",
        " \n",
        "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
        "\n",
        "åœ¨ç¬¬2æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å‡ ç§è‡ªå®šä¹‰å›¾çŠ¶æ€å’Œå†…å­˜çš„æ–¹æ³•ã€‚\n",
        "\n",
        "æˆ‘ä»¬é€æ­¥æ„å»ºäº†ä¸€ä¸ªå¸¦æœ‰å¤–éƒ¨å­˜å‚¨å™¨çš„èŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥ç»´æŒé•¿æ—¶é—´çš„å¯¹è¯ã€‚\n",
        "\n",
        "## ç›®æ ‡ï¼ˆGoalsï¼‰\n",
        "\n",
        "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
        "\n",
        "æœ¬æ¨¡å—å°†æ·±å…¥æ¢è®¨ `human-in-the-loop`ï¼Œå®ƒåŸºäºå†…å­˜æ„å»ºï¼Œå¹¶å…è®¸ç”¨æˆ·ä»¥å¤šç§æ–¹å¼ç›´æ¥ä¸å›¾å½¢äº¤äº’ã€‚\n",
        "\n",
        "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution.\n",
        "\n",
        "ä¸ºäº†ä¸º `human-in-the-loop` åšé“ºå«ï¼Œæˆ‘ä»¬å°†é¦–å…ˆæ·±å…¥æ¢è®¨æµå¼å¤„ç†ï¼Œå®ƒæä¾›äº†å¤šç§æ–¹æ³•æ¥åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å¯è§†åŒ–å›¾è¾“å‡ºï¼ˆä¾‹å¦‚ï¼ŒèŠ‚ç‚¹çŠ¶æ€æˆ–èŠå¤©æ¨¡å‹ä»¤ç‰Œï¼‰ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
      "metadata": {},
      "source": [
        "## æµå¼ä¼ è¾“ï¼ˆStreamingï¼‰\n",
        "\n",
        "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "LangGraph æ˜¯ä½¿ç”¨ [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming) æ„å»ºçš„ã€‚\n",
        "\n",
        "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. \n",
        "\n",
        "è®©æˆ‘ä»¬ä»ç¬¬2æ¨¡å—è®¾ç½®èŠå¤©æœºå™¨äººï¼Œå¹¶å±•ç¤ºåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä»å›¾ä¸­æµå¼ä¼ è¾“è¾“å‡ºçš„å„ç§æ–¹æ³•ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b430d92-f595-4322-a56e-06de7485daa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0682fc",
      "metadata": {},
      "source": [
        "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. \n",
        "\n",
        "è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨ `RunnableConfig` ä¸ `call_model` æ¥å¯ç”¨æŒ‰ä»¤ç‰Œæµå¼ä¼ è¾“ã€‚è¿™æ˜¯ [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/)ã€‚æˆ‘ä»¬å°†å…¶åŒ…å«åœ¨å†…ï¼Œä»¥é˜²æ‚¨åœ¨ CoLab ä¸­è¿è¡Œæ­¤ç¬”è®°æœ¬ï¼Œå®ƒå°†ä½¿ç”¨ python 3.xã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "# LLMæ¨¡å‹\n",
        "model = ChatOpenAI(\n",
        "    model=\"qwen-plus-2025-04-28\",\n",
        "    api_key=\"sk-ba2dda3817f145d7af141fdf32e31d90\",\n",
        "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
        ")\n",
        "\n",
        "# çŠ¶æ€\n",
        "class State(MessagesState):\n",
        "    summary: str\n",
        "\n",
        "# å®šä¹‰è°ƒç”¨æ¨¡å‹çš„é€»è¾‘\n",
        "def call_model(state: State, config: RunnableConfig):\n",
        "    \n",
        "    # è·å–å·²å­˜åœ¨çš„æ‘˜è¦\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # å¦‚æœæœ‰æ‘˜è¦ï¼Œåˆ™æ·»åŠ å®ƒ\n",
        "    if summary:\n",
        "        \n",
        "        # å°†æ‘˜è¦æ·»åŠ åˆ°ç³»ç»Ÿæ¶ˆæ¯ä¸­\n",
        "        system_message = f\"è¿™æ˜¯å…ˆå‰å¯¹è¯çš„æ‘˜è¦: {summary}\"\n",
        "\n",
        "        # å°†æ‘˜è¦é™„åŠ åˆ°ä»»ä½•è¾ƒæ–°çš„æ¶ˆæ¯ä¹‹å‰\n",
        "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
        "    \n",
        "    else:\n",
        "        messages = state[\"messages\"]\n",
        "    \n",
        "    response = model.invoke(messages, config)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def summarize_conversation(state: State):\n",
        "    \n",
        "    # é¦–å…ˆï¼Œæˆ‘ä»¬è·å–ä»»ä½•å·²æœ‰çš„æ‘˜è¦\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # åˆ›å»ºæˆ‘ä»¬çš„æ‘˜è¦æç¤º\n",
        "    if summary:\n",
        "        \n",
        "        # æ‘˜è¦å·²å­˜åœ¨\n",
        "        summary_message = (\n",
        "            f\"è¿™æ˜¯è¿„ä»Šä¸ºæ­¢çš„å¯¹è¯æ‘˜è¦: {summary}\\n\\n\"\n",
        "            \"è¯·ç»“åˆä»¥ä¸Šæ–°æ¶ˆæ¯æ‰©å±•æ­¤æ‘˜è¦:\"\n",
        "        )\n",
        "        \n",
        "    else:\n",
        "        summary_message = \"ä¸ºä»¥ä¸Šå¯¹è¯åˆ›å»ºä¸€ä¸ªæ‘˜è¦:\"\n",
        "\n",
        "    # å°†æç¤ºæ·»åŠ åˆ°æˆ‘ä»¬çš„å†å²è®°å½•ä¸­\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "    \n",
        "    # åˆ é™¤é™¤äº†æœ€è¿‘2æ¡ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
        "\n",
        "# å†³å®šæ˜¯ç»“æŸè¿˜æ˜¯æ€»ç»“å¯¹è¯\n",
        "def should_continue(state: State):\n",
        "    \n",
        "    \"\"\"è¿”å›ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹ã€‚\"\"\"\n",
        "    \n",
        "    messages = state[\"messages\"]\n",
        "    \n",
        "    # å¦‚æœæ¶ˆæ¯è¶…è¿‡å…­æ¡ï¼Œæˆ‘ä»¬å°±æ€»ç»“å¯¹è¯\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "    \n",
        "    # å¦åˆ™æˆ‘ä»¬å°±å¯ä»¥ç»“æŸäº†\n",
        "    return END\n",
        "\n",
        "# å®šä¹‰ä¸€ä¸ªæ–°çš„å›¾\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# å°†å…¥å£ç‚¹è®¾ç½®ä¸º conversation\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# ç¼–è¯‘\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f847a787-b301-488c-9b58-cba9f389f55d",
      "metadata": {},
      "source": [
        "### æµå¼ä¼ è¾“å®Œæ•´çŠ¶æ€ï¼ˆStreaming full stateï¼‰\n",
        "\n",
        "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥è°ˆè°ˆ [æµå¼ä¼ è¾“æˆ‘ä»¬çš„å›¾çŠ¶æ€](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming) çš„æ–¹æ³•ã€‚\n",
        "\n",
        "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
        " \n",
        "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
        " \n",
        "* `values`: This streams the full state of the graph after each node is called.\n",
        "* `updates`: This streams updates to the state of the graph after each node is called.\n",
        "\n",
        "`.stream` å’Œ `.astream` æ˜¯ç”¨äºæµå¼è¿”å›ç»“æœçš„åŒæ­¥å’Œå¼‚æ­¥æ–¹æ³•ã€‚\n",
        "\n",
        "LangGraph æ”¯æŒå‡ ç§ [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) ç”¨äº [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/)ï¼š\n",
        "\n",
        "*`values`ï¼šè¿™å°†åœ¨æ¯ä¸ªèŠ‚ç‚¹è¢«è°ƒç”¨åæµå¼ä¼ è¾“å›¾çš„å®Œæ•´çŠ¶æ€ã€‚* `updates`ï¼šè¿™å°†åœ¨æ¯ä¸ªèŠ‚ç‚¹è¢«è°ƒç”¨åæµå¼ä¼ è¾“å›¾çš„çŠ¶æ€æ›´æ–°ã€‚\n",
        "\n",
        "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
        "\n",
        "Let's look at `stream_mode=\"updates\"`.\n",
        "\n",
        "è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ `stream_mode=\"updates\"`ã€‚\n",
        "\n",
        "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
        "\n",
        "å› ä¸ºæˆ‘ä»¬ä½¿ç”¨ `updates` è¿›è¡Œæµå¼ä¼ è¾“ï¼Œæ‰€ä»¥åªæœ‰åœ¨å›¾ä¸­çš„èŠ‚ç‚¹è¿è¡Œåï¼Œæˆ‘ä»¬æ‰èƒ½çœ‹åˆ°çŠ¶æ€çš„æ›´æ–°ã€‚\n",
        "\n",
        "Each `chunk` is a dict with `node_name` as the key and the updated state as the value.\n",
        "\n",
        "æ¯ä¸ª `chunk` æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä»¥ `node_name` ä¸ºé”®ï¼Œæ›´æ–°åçš„çŠ¶æ€ä¸ºå€¼ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'conversation': {'messages': AIMessage(content='ä½ å¥½ï¼Œzxjï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï½æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 576, 'total_tokens': 592, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen-plus-2025-04-28', 'system_fingerprint': None, 'id': 'chatcmpl-891471ae-2fe8-9b3d-b5f7-f4fcd55a4e16', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f36409f3-af43-4e9b-8a46-39646ad7c106-0', usage_metadata={'input_tokens': 576, 'output_tokens': 16, 'total_tokens': 592, 'input_token_details': {}, 'output_token_details': {}})}}\n"
          ]
        }
      ],
      "source": [
        "# Create a thread\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"ä½ å¥½æˆ‘æ˜¯zxj\")]}, config, stream_mode=\"updates\"):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
      "metadata": {},
      "source": [
        "Let's now just print the state update.\n",
        "\n",
        "ç°åœ¨æˆ‘ä»¬ç›´æ¥æ‰“å°çŠ¶æ€æ›´æ–°ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c859c777-cb12-4682-9108-6b367e597b81",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "ä½ å¥½å‘€ï¼Œzxjï¼å†æ¬¡è§åˆ°ä½ çœŸé«˜å…´ï½ğŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ\n"
          ]
        }
      ],
      "source": [
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"ä½ å¥½æˆ‘æ˜¯zxj\")]}, config, stream_mode=\"updates\"):\n",
        "    chunk['conversation'][\"messages\"].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "583bf219-6358-4d06-ae99-c40f43569fda",
      "metadata": {},
      "source": [
        "Now, we can see `stream_mode=\"values\"`.\n",
        "\n",
        "ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° `stream_mode=\"values\"`.\n",
        "\n",
        "This is the `full state` of the graph after the `conversation` node is called.\n",
        "\n",
        "è¿™æ˜¯åœ¨ `conversation` èŠ‚ç‚¹è¢«è°ƒç”¨åï¼Œå›¾çš„ `full state`ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "ä½ å¥½æˆ‘æ˜¯zxj\n",
            "---------------------------------------------------------------------------\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "ä½ å¥½æˆ‘æ˜¯zxj\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "ä½ å¥½ï¼Œzxjï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Start conversation, again\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"ä½ å¥½æˆ‘æ˜¯zxj\")\n",
        "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    for m in event['messages']:\n",
        "        m.pretty_print()\n",
        "    print(\"---\"*25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
      "metadata": {},
      "source": [
        "### æµå¼ä¼ è¾“ä»¤ç‰Œï¼ˆStreaming tokensï¼‰\n",
        "\n",
        "We often want to stream more than graph state.\n",
        "\n",
        "æˆ‘ä»¬é€šå¸¸å¸Œæœ›ä¼ è¾“çš„å†…å®¹ä¸ä»…ä»…æ˜¯å›¾å½¢çŠ¶æ€ã€‚\n",
        "\n",
        "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
        "\n",
        "ç‰¹åˆ«æ˜¯ï¼Œå¯¹äºèŠå¤©æ¨¡å‹è°ƒç”¨ï¼Œé€šå¸¸ä¼šåœ¨ç”Ÿæˆä»¤ç‰Œçš„åŒæ—¶ä»¥æµå¼ä¼ è¾“çš„æ–¹å¼å¤„ç†è¿™äº›ä»¤ç‰Œã€‚\n",
        "\n",
        "We can do this [using the PROTECTED$11$ method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥è¿™æ ·åš [using the PROTECTED$11$ method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node)ï¼Œå®ƒä¼šåœ¨èŠ‚ç‚¹å†…éƒ¨äº‹ä»¶å‘ç”Ÿæ—¶å®æ—¶å›ä¼ äº‹ä»¶ï¼\n",
        "\n",
        "Each event is a dict with a few keys:\n",
        " \n",
        "* `event`: This is the type of event that is being emitted. \n",
        "* `name`: This is the name of event.\n",
        "* `data`: This is the data associated with the event.\n",
        "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
        "\n",
        "æ¯ä¸ªäº‹ä»¶æ˜¯ä¸€ä¸ªåŒ…å«å‡ ä¸ªé”®çš„å­—å…¸ï¼š\n",
        "\n",
        "*`event`ï¼šè¿™æ˜¯æ­£åœ¨å‘å‡ºçš„äº‹ä»¶çš„ç±»å‹ã€‚* `name`ï¼šè¿™æ˜¯äº‹ä»¶çš„åç§°ã€‚\n",
        "*`data`ï¼šè¿™æ˜¯ä¸äº‹ä»¶ç›¸å…³è”çš„æ•°æ®ã€‚* `metadata`ï¼šåŒ…å« `langgraph_node`ï¼Œå³å‘å‡ºäº‹ä»¶çš„èŠ‚ç‚¹ã€‚\n",
        "\n",
        "Let's have a look.\n",
        "\n",
        "è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node: . Type: on_chain_start. Name: LangGraph\n",
            "Node: conversation. Type: on_chain_start. Name: conversation\n",
            "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chain_start. Name: should_continue\n",
            "Node: conversation. Type: on_chain_end. Name: should_continue\n",
            "Node: conversation. Type: on_chain_stream. Name: conversation\n",
            "Node: conversation. Type: on_chain_end. Name: conversation\n",
            "Node: . Type: on_chain_stream. Name: LangGraph\n",
            "Node: . Type: on_chain_end. Name: LangGraph\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "input_message = HumanMessage(content=\"lolæ˜¯ä»€ä¹ˆ\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
      "metadata": {},
      "source": [
        "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
        "\n",
        "è¦ç‚¹æ˜¯ï¼Œå›¾è¡¨ä¸­èŠå¤©æ¨¡å‹çš„ä»¤ç‰Œå…·æœ‰ `on_chat_model_stream` ç±»å‹ã€‚\n",
        "\n",
        "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `event['metadata']['langgraph_node']` æ¥é€‰æ‹©è¦æµå¼çš„èŠ‚ç‚¹ã€‚\n",
        "\n",
        "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. \n",
        "\n",
        "å¹¶ä¸”æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `event['data']` æ¥è·å–æ¯ä¸ªäº‹ä»¶çš„å®é™…æ•°æ®ï¼Œè€Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®æ˜¯ä¸€ä¸ª `AIMessageChunk`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€Š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‹±é›„è”ç›Ÿã€‹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼ˆ**', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='League of Legends', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='**ï¼Œç®€ç§° **Lo', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='L**ï¼‰æ˜¯ä¸€æ¬¾', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç”± **Riot Games', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='** å¼€å‘å¹¶', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è¿è¥çš„ **å¤šäºº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='åœ¨çº¿æˆ˜æœ¯ç«æŠ€æ¸¸æˆ**', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼ˆMOBAï¼Œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='Multiplayer Online Battle', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' Arenaï¼‰ã€‚å®ƒåœ¨å…¨çƒ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='èŒƒå›´å†…æ‹¥æœ‰åºå¤§çš„ç©å®¶ç¾¤ä½“å’Œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç”µç«ç”Ÿæ€ï¼Œæ˜¯ä¸­å›½', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¹ƒè‡³å…¨ä¸–ç•Œæœ€å—æ¬¢è¿çš„ç”µå­', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¸¸æˆä¹‹ä¸€ã€‚\\n\\n---\\n\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='## ğŸŒ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' æ¸¸æˆåŸºæœ¬ä¿¡æ¯', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n\\n- **å¼€å‘å•†', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='**ï¼šRiot Gamesï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ‹³å¤´æ¸¸æˆï¼‰\\n- **å‘è¡Œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ—¶é—´**ï¼š2', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='009å¹´1', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='0æœˆ27æ—¥\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='- **å¹³å°**ï¼šWindows', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' PCã€Macï¼ˆéƒ¨åˆ†', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='åŒºåŸŸï¼‰ã€ç§»åŠ¨ç«¯ï¼ˆæ‰‹æ¸¸', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€Šè‹±é›„è”ç›Ÿï¼š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¿€æ–—å³¡è°·ã€‹ï¼‰\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' **æ¸¸æˆç±»å‹**ï¼šMO', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='BAï¼ˆå¤šäººåœ¨çº¿æˆ˜æœ¯ç«æŠ€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¸¸æˆï¼‰\\n- **æ¸¸æˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¨¡å¼**ï¼š\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' å¬å”¤å¸ˆå³¡è°·ï¼ˆ5', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='v5 ä¸»æˆ˜åœº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰\\n  - ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ— é™ç«åŠ›ã€æ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='åœ°å¤§ä¹±æ–—ã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ARAMï¼ˆAll Random', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' All Midï¼‰\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' äº‘é¡¶ä¹‹å¼ˆï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‡ªèµ°æ£‹æ¨¡å¼', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼Œç‹¬ç«‹æ¸¸æˆï¼‰\\n\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='---\\n\\n##', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ® æ¸¸æˆç©æ³•', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç®€ä»‹\\n\\n###', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ° æ ¸å¿ƒç›®æ ‡', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n- ä¸¤æ”¯', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='äº”äººé˜Ÿä¼åœ¨', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='åä¸ºâ€œå¬å”¤å¸ˆå³¡è°·', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='â€çš„åœ°å›¾ä¸Šå¯¹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æˆ˜ã€‚\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ç›®æ ‡æ˜¯æ‘§æ¯æ•Œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ–¹ä¸»åŸºåœ°ï¼ˆN', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='exusï¼‰ã€‚\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ç©å®¶æ§åˆ¶', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸€åâ€œè‹±é›„â€ï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='Championï¼‰ï¼Œé€šè¿‡', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å‡»æ€å°å…µã€é‡', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ€ªã€æ•Œæ–¹è‹±é›„æ¥', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è·å¾—é‡‘å¸å’Œç»éªŒ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼Œæå‡å®åŠ›ã€‚\\n\\n###', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ§± æ¸¸æˆæœºåˆ¶', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n- **è‹±é›„æŠ€èƒ½', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='**ï¼šæ¯ä¸ªè‹±é›„æœ‰4', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸ªæŠ€èƒ½ï¼ˆQ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€Wã€Eã€R', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼Œå…¶ä¸­Rä¸º', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç»ˆææŠ€èƒ½ï¼‰ã€‚\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' **ç¬¦æ–‡ç³»ç»Ÿ**', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼šç©å®¶å¯è‡ªå®šä¹‰', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç¬¦æ–‡é¡µï¼Œå½±å“', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‹±é›„å±æ€§å’Œæˆ˜æ–—é£æ ¼ã€‚\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='- **è£…å¤‡ç³»ç»Ÿ**ï¼š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='é€šè¿‡è´­ä¹°è£…å¤‡å¢å¼º', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‹±é›„èƒ½åŠ›ã€‚\\n- **åœ°å›¾', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å…ƒç´ **ï¼š\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' å°å…µï¼ˆå…µçº¿æ¨è¿›', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰\\n  - ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='é‡æ€ªï¼ˆé‡åŒº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='èµ„æºï¼‰\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' é¾™ï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å…ƒç´ é¾™ã€è¿œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¤é¾™ï¼‰\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' çº³ä»€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç”·çˆµï¼ˆå¤§', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='é¾™ï¼‰\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' é˜²å¾¡å¡”', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€æ°´æ™¶ã€å…µ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è¥ã€åŸºåœ°\\n\\n---\\n\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='## ğŸ§‘', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\u200dğŸ¤', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\u200dğŸ§‘ è‹±é›„åˆ†ç±»', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼ˆè§’è‰²å®šä½ï¼‰\\n\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' å®šä½ |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ç‰¹ç‚¹ |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' å¸¸è§è‹±é›„ |\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='------|------|----------|\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='| ä¸Šå•ï¼ˆTop', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰ | å¦', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å…‹ã€æˆ˜å£«ã€å•', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æŒ‘èƒ½åŠ›å¼º |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' è´¾å…‹æ–¯ã€ç›–', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¼¦ã€å‰‘å§¬ |\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' æ‰“é‡ï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='Jungleï¼‰ |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' æ¸¸èµ°æ”¯æ´', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€æ§å›¾ã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='gank |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' æé’ã€è‰¾', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å…‹ã€ä½›è€¶æˆˆ |\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='| ä¸­å•ï¼ˆMid', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰ | é«˜çˆ†å‘', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€æ¸¸èµ°èƒ½åŠ›å¼º', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | ä¹èŠ™å…°', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€é˜¿ç‹¸ã€è¾›', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¾·æ‹‰ |\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' å°„æ‰‹ï¼ˆADCï¼‰', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | è¿œç¨‹è¾“å‡º', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€åæœŸæ ¸å¿ƒ |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' è–‡æ©ã€é‡‘', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å…‹ä¸ã€è‰¾', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¸Œ |\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' è¾…åŠ©ï¼ˆSupport', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰ | ä¿æŠ¤é˜Ÿå‹ã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ§åˆ¶ã€æ²»ç–— |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' é”¤çŸ³ã€å¸ƒ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='é‡ŒèŒ¨ã€ç´¢', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ‹‰å¡ |\\n\\n---\\n\\n##', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ† ç”µç«ä¸', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='èµ›äº‹ä½“ç³»\\n\\nã€Š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‹±é›„è”ç›Ÿã€‹æ˜¯å…¨çƒæœ€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æˆåŠŸçš„ç”µç«é¡¹ç›®ä¹‹ä¸€ï¼Œå…¶', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='èµ›äº‹ä½“ç³»åŒ…æ‹¬ï¼š\\n\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='- **å…¨çƒæ€»å†³èµ›ï¼ˆWorld', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='sï¼‰**ï¼š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¹´åº¦æœ€é«˜çº§åˆ«èµ›äº‹ï¼Œè¢«èª‰ä¸º', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='â€œç”µç«ä¸–ç•Œæ¯â€ã€‚\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' **å­£ä¸­é‚€è¯·èµ›ï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='MSIï¼‰**ï¼šå„å›½', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='èµ›åŒºæ˜¥å­£èµ›å† å†›å‚èµ›', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€‚\\n- **å„', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='èµ›åŒºè”èµ›**ï¼š\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' LPLï¼ˆä¸­å›½å¤§é™†', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰\\n  - L', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='CKï¼ˆéŸ©å›½ï¼‰\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' LCSï¼ˆåŒ—ç¾ï¼‰\\n  -', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' LECï¼ˆæ¬§æ´²ï¼‰\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='  - å…¶ä»–åœ°åŒº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è”èµ›\\n\\n### ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸­å›½LPLèµ›åŒº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n- ä»£è¡¨', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æˆ˜é˜Ÿï¼šEDGã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='RNGã€JD', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='Gã€WEã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='BLGã€TES', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç­‰\\n- ä¸­å›½', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æˆ˜é˜Ÿæ›¾å¤šæ¬¡è·å¾—', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸–ç•Œå† å†›ï¼ˆå¦‚ï¼š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='EDG 202', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='1å¹´ã€JD', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='G 2023', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¹´ï¼‰\\n\\n---\\n\\n##', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ“š æ¸¸æˆèƒŒæ™¯', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸–ç•Œè§‚\\n\\nã€Šè‹±é›„è”ç›Ÿã€‹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ‹¥æœ‰ä¸°å¯Œçš„èƒŒæ™¯è®¾å®š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼Œå‘ç”Ÿåœ¨åä¸º **ç¬¦', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ–‡ä¹‹åœ°ï¼ˆRun', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='eterraï¼‰** çš„å¥‡å¹»', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸–ç•Œä¸­ï¼ŒåŒ…æ‹¬', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¤šä¸ªåœ°åŒºï¼š\\n\\n- **å¾·', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç›è¥¿äºš**ï¼ˆ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ­£ä¹‰ä¹‹é‚¦ï¼‰\\n- **', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è¯ºå…‹è¨æ–¯', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='**ï¼ˆæˆ˜äº‰å¸å›½', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰\\n- **è‰¾', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¬§å°¼äºš**ï¼ˆä¸œæ–¹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ­¦é“åœ£åœ°ï¼‰\\n- **', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¯”å°”å‰æ²ƒ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç‰¹**ï¼ˆæ··ä¹±', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='éƒ½å¸‚ï¼‰\\n- **', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç¥–å®‰**ï¼ˆç§‘æŠ€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¹‹åŸï¼‰\\n- **', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¼—é›·å°”å“', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¾·**ï¼ˆå†°é›ª', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¤§é™†ï¼‰\\n- **', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æš—å½±å²›**ï¼ˆäº¡', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='çµä¹‹åœ°ï¼‰\\n\\næ¯ä¸ª', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‹±é›„éƒ½æœ‰è‡ªå·±çš„èƒŒæ™¯æ•…äº‹ï¼Œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸”ä¸æ¸¸æˆè¡ç”Ÿ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä½œå“ï¼ˆå¦‚åŠ¨ç”»', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€ŠåŒåŸä¹‹æˆ˜ã€‹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€å°è¯´ã€æ¼«ç”»', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼‰ç›¸äº’å…³è”ã€‚\\n\\n---\\n\\n##', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ“±', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' æ‰‹æ¸¸ç‰ˆï¼š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è‹±é›„è”ç›Ÿï¼šæ¿€æ–—å³¡è°·', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n\\n- **ä¸Šçº¿', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ—¶é—´**ï¼š202', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='0å¹´èµ·é™†ç»­ä¸Šçº¿\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' **ç©æ³•**ï¼šç®€åŒ–', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç‰ˆçš„å¬å”¤å¸ˆå³¡è°·', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼Œé€‚åˆç§»åŠ¨ç«¯æ“ä½œ\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='- **æ”¯æŒå¹³å°', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='**ï¼šiOSã€Android\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='- **ä¸­æ–‡å', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='**ï¼šã€Šè‹±é›„è”ç›Ÿï¼š', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ¿€æ–—å³¡è°·ã€‹\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='- **å›½æœç”±', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='è…¾è®¯ä»£ç†ï¼Œå·²äº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='2022å¹´æ­£å¼', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä¸Šçº¿**\\n\\n---\\n\\n##', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸ¨ æ¸¸æˆç‰¹è‰²', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n\\n- **æŒç»­', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ›´æ–°**ï¼šæ¯å‘¨', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ›´æ–°ç‰ˆæœ¬ï¼Œå¹³è¡¡è‹±é›„', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€æœºåˆ¶\\n- **ä¸°å¯Œ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='çš®è‚¤**ï¼šä¸ªæ€§åŒ–', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¤–è§‚ï¼Œä¸å½±å“å±æ€§', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='\\n- **ç¤¾åŒº', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='æ´»è·ƒ**ï¼šæœ‰', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å¤§é‡ç©å®¶è‡ªåˆ¶å†…å®¹ã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ç›´æ’­ã€è§£è¯´ã€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='äºŒæ¬¡åˆ›ä½œ\\n-', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' **IPæ‰©å±•**ï¼šè¡ç”Ÿ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='åŠ¨ç”»ã€æ¼«ç”»ã€å°è¯´', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ã€éŸ³ä¹ç­‰\\n\\n---\\n\\n##', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' ğŸŒŸ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' çŸ¥åä¸­å›½é€‰æ‰‹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ï¼ˆLPLï¼‰\\n\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' é€‰æ‰‹ | ', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='ä½ç½® | æ‰€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å±æˆ˜é˜Ÿï¼ˆæˆªè‡³', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='2024ï¼‰ |\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='|------|------', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='|----------------------|\\n| U', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='zi | ADC | é€€å½¹', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' |\\n| TheSh', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='y | ä¸Šå• | W', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='BG |\\n| Rookie', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | ä¸­å• | N', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='IP |\\n| Knight', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | ä¸­å• | JD', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='G |\\n| Xiao', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='AL | è€', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='å°† | é€€å½¹ |\\n', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='| Meiko |', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' è¾…åŠ© | ED', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='G |\\n| Jack', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='eyLove | ADC', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | TES |\\n| Sc', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content='out | ä¸­å• | LNG', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' |\\n| Kanavi', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | æ‰“é‡', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n",
            "{'chunk': AIMessageChunk(content=' | JDG |\\n|', additional_kwargs={}, response_metadata={}, id='run--96165753-d1b7-4844-906a-7c61da31915d')}\n"
          ]
        },
        {
          "ename": "CancelledError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m4\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m      3\u001b[39m input_message = HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mä¸ºæˆ‘ä»‹ç»lol\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph.astream_events({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [input_message]}, config, version=\u001b[33m\"\u001b[39m\u001b[33mv2\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# ä»ç‰¹å®šèŠ‚ç‚¹è·å–èŠå¤©æ¨¡å‹ç”Ÿæˆçš„ Token\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event[\u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mon_chat_model_stream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33mlanggraph_node\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) == node_to_stream:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain_core/runnables/base.py:1403\u001b[39m, in \u001b[36mRunnable.astream_events\u001b[39m\u001b[34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[39m\n\u001b[32m   1400\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[32m   1402\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclosing(event_stream):\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_stream:\n\u001b[32m   1404\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain_core/tracers/event_stream.py:989\u001b[39m, in \u001b[36m_astream_events_implementation_v2\u001b[39m\u001b[34m(runnable, value, config, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[39m\n\u001b[32m    986\u001b[39m first_event_run_id = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_streamer:\n\u001b[32m    990\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first_event_sent:\n\u001b[32m    991\u001b[39m             first_event_sent = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/langchain_core/tracers/memory_stream.py:97\u001b[39m, in \u001b[36m_ReceiveStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aiter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> AsyncIterator[T]:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m         item = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._queue.get()\n\u001b[32m     98\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m._done:\n\u001b[32m     99\u001b[39m             \u001b[38;5;28mself\u001b[39m._is_closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/asyncio/queues.py:158\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._getters.append(getter)\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    160\u001b[39m     getter.cancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
            "\u001b[31mCancelledError\u001b[39m: "
          ]
        }
      ],
      "source": [
        "node_to_stream = 'conversation'\n",
        "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "input_message = HumanMessage(content=\"ä¸ºæˆ‘ä»‹ç»lol\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # ä»ç‰¹å®šèŠ‚ç‚¹è·å–èŠå¤©æ¨¡å‹ç”Ÿæˆçš„ Token\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        print(event[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
      "metadata": {},
      "source": [
        "As you see above, just use the `chunk` key to get the `AIMessageChunk`.\n",
        "\n",
        "å¦‚ä¸Šæ‰€è¿°ï¼Œåªéœ€ä½¿ç”¨ `chunk` å¯†é’¥å³å¯è·å– `AIMessageChunk`ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|å½“ç„¶|å¯ä»¥|ï¼**|ã€Š|è‹±é›„è”ç›Ÿã€‹**|ï¼ˆLeague of Legendsï¼Œç®€ç§°|**LoL**|ï¼‰æ˜¯ä¸€æ¬¾éå¸¸å—æ¬¢è¿çš„|å¤šäººåœ¨çº¿æˆ˜æœ¯ç«æŠ€|æ¸¸æˆï¼ˆMOBA|ï¼‰ï¼Œç”±ç¾å›½å…¬å¸**|Riot Games**ï¼ˆæ‹³å¤´|æ¸¸æˆï¼‰å¼€å‘ï¼Œ|äº200|9å¹´æ­£å¼ä¸Šçº¿|ã€‚è¿™æ¬¾æ¸¸æˆåœ¨å…¨çƒèŒƒå›´å†…æ‹¥æœ‰|åºå¤§çš„ç©å®¶ç¾¤ä½“å’Œ|ç”µç«èµ›äº‹ä½“ç³»ï¼Œæ˜¯ä¸­å›½|ä¹ƒè‡³å…¨çƒæœ€å—æ¬¢è¿çš„ç”µç«é¡¹ç›®|ä¹‹ä¸€ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "##| ğŸŒ| æ¸¸æˆåŸºæœ¬ä¿¡æ¯\n",
            "\n",
            "- **|æ¸¸æˆç±»å‹**ï¼šMO|BAï¼ˆå¤šäººåœ¨çº¿æˆ˜æœ¯ç«æŠ€|æ¸¸æˆï¼‰\n",
            "- **å¼€å‘å•†**|ï¼šRiot Gamesï¼ˆæ‹³å¤´|æ¸¸æˆï¼‰\n",
            "- **|ä¸Šçº¿æ—¶é—´**ï¼š|2009|å¹´10æœˆ2|7æ—¥\n",
            "- **å¹³å°|**ï¼šWindows PC|ã€Macï¼ˆé€šè¿‡|å…¼å®¹å±‚ï¼‰ã€æ‰‹æ¸¸|ï¼ˆã€Šè‹±é›„è”ç›Ÿï¼š|æ¿€æ–—å³¡è°·ã€‹ï¼‰\n",
            "|- **å›½æœä»£ç†|**ï¼šè…¾è®¯ï¼ˆä¸­å›½å¤§é™†|åœ°åŒºï¼‰\n",
            "\n",
            "---\n",
            "\n",
            "##| ğŸ® æ¸¸|æˆç©æ³•ç®€ä»‹\n",
            "\n",
            "åœ¨|ã€Šè‹±é›„è”ç›Ÿã€‹ä¸­ï¼Œ|ä¸¤æ”¯å„ç”±|5åç©å®¶ç»„æˆçš„|é˜Ÿä¼åœ¨ä¸€å¼ åä¸ºâ€œå¬å”¤|å¸ˆå³¡è°·â€çš„åœ°å›¾ä¸Šè¿›è¡Œ|å¯¹æŠ—ã€‚ç›®æ ‡æ˜¯é€šè¿‡å›¢é˜Ÿ|åˆä½œã€ç­–ç•¥ä¸|æ“ä½œï¼Œæ‘§æ¯å¯¹æ–¹|çš„ä¸»åŸºåœ°â€œ|æ°´æ™¶æ¢çº½â€ï¼ˆN|exusï¼‰ã€‚\n",
            "\n",
            "###| æ ¸å¿ƒæœºåˆ¶|åŒ…æ‹¬ï¼š\n",
            "\n",
            "- **è‹±é›„|é€‰æ‹©**ï¼šç›®å‰|æ¸¸æˆä¸­æœ‰è¶…è¿‡16|0ä½é£æ ¼å„å¼‚çš„è‹±é›„|ï¼ˆç§°ä¸ºâ€œè‹±é›„|â€æˆ–â€œè‹±é›„è§’è‰²|â€ï¼‰ï¼Œæ¯ä½è‹±é›„æœ‰|ç‹¬ç‰¹çš„æŠ€èƒ½å’Œå®šä½|ã€‚\n",
            "- **åœ°å›¾|ä¸ç›®æ ‡**ï¼š\n",
            " | - ä¸»åœ°å›¾â€œ|å¬å”¤å¸ˆå³¡è°·â€æœ‰|ä¸‰æ¡ä¸»è¦è·¯çº¿ï¼ˆä¸Š|è·¯ã€ä¸­è·¯ã€ä¸‹|è·¯ï¼‰ï¼Œä¸­é—´æœ‰é‡åŒº|ã€‚\n",
            "  - ä¸¤|é˜Ÿä»å„è‡ªçš„åŸºåœ°å‡ºå‘ï¼Œ|é€šè¿‡å‡»æ€å°å…µã€|é‡æ€ªã€æ•Œ|æ–¹è‹±é›„è·å–é‡‘å¸|å’Œç»éªŒï¼Œå‡çº§æŠ€èƒ½|ã€è´­ä¹°è£…å¤‡ã€‚\n",
            " | - æœ€ç»ˆç›®æ ‡æ˜¯æ‘§æ¯|æ•Œæ–¹æ°´æ™¶æ¢çº½ã€‚\n",
            "\n",
            "|- **èƒœåˆ©æ¡ä»¶**ï¼š|æ‘§æ¯æ•Œæ–¹åŸºåœ°|çš„æ ¸å¿ƒå»ºç­‘â€œæ°´æ™¶æ¢çº½â€ã€‚\n",
            "\n",
            "|---\n",
            "\n",
            "##| ğŸ§‘â€ğŸ¤|â€ğŸ§‘| æ¸¸æˆæ¨¡å¼\n",
            "\n",
            "|é™¤äº†ç»å…¸çš„5v5|â€œå¬å”¤å¸ˆå³¡è°·|â€æ¨¡å¼ï¼Œæ¸¸æˆ|è¿˜æä¾›äº†å¤šç§å¨±ä¹|å’Œç»ƒä¹ æ¨¡å¼ï¼š\n",
            "\n",
            "|| æ¨¡å¼åç§°| | ç®€ä»‹| |\n",
            "|----------|------|\n",
            "|| å¬å”¤|å¸ˆå³¡è°·ï¼ˆ5v5|ï¼‰ | ç»å…¸å¯¹|æˆ˜æ¨¡å¼ï¼Œä¸‰æ¡|è·¯çº¿+é‡åŒº |\n",
            "|| ARAMï¼ˆAll| Random All Midï¼‰ || éšæœºè‹±é›„ï¼Œ|å›ºå®šåœ°å›¾â€œåš|å“­æ·±æ¸Šâ€ |\n",
            "|| 6v6| äº’ä¸ç›¸è®©|ï¼ˆç†”æ¸£ä¹‹|å½¹ï¼‰ | æ–°|æ¨¡å¼ï¼Œå¼ºè°ƒå›¢é˜Ÿé…åˆ|ä¸èµ„æºäº‰å¤º |\n",
            "|| æ— é™ç«åŠ› || æŠ€èƒ½æ— |CDï¼Œé€‚åˆå¨±ä¹| |\n",
            "| äºº|æœºå¯¹æˆ˜ || é€‚åˆæ–°æ‰‹ç»ƒä¹  |\n",
            "|| å¤§ä¹±æ–—ï¼ˆ|URFï¼‰ || ç‰¹æ®Šè§„åˆ™ï¼ŒæŠ€èƒ½CD|æçŸ­ï¼Œä¹è¶£|åè¶³ |\n",
            "\n",
            "---\n",
            "\n",
            "##| ğŸ¦¸ è‹±é›„åˆ†ç±»|ï¼ˆè§’è‰²å®šä½ï¼‰\n",
            "\n",
            "è‹±é›„|æŒ‰å®šä½å¯åˆ†ä¸ºä»¥ä¸‹å‡ ç±»|ï¼š\n",
            "\n",
            "| ç±»å‹ || ç‰¹ç‚¹ | |ä»£è¡¨è‹±é›„ |\n",
            "|------||------|----------|\n",
            "|| æˆ˜å£«ï¼ˆ|Fighterï¼‰ || å‡è¡¡|å‹ï¼Œæ”»å®ˆ|å…¼å¤‡ | äºš|ç´¢ã€é”é›¯ |\n",
            "|| åˆºå®¢ï¼ˆ|Assassinï¼‰ || é«˜çˆ†å‘ï¼Œç§’æ€åæ’| | åŠ«ã€|å¡å…¹å…‹ |\n",
            "|| æ³•å¸ˆï¼ˆMageï¼‰ || è¿œç¨‹æ³•|æœ¯è¾“å‡º | ä¹|èŠ™å…°ã€ç»´|å…‹æ‰˜ |\n",
            "|| å°„æ‰‹ï¼ˆMarks|manï¼‰ || è¿œç¨‹ç‰©ç†è¾“å‡ºï¼ŒåæœŸ|æ ¸å¿ƒ | é‡‘|å…‹ä¸ã€è–‡|æ© |\n",
            "|| å¦å…‹ï¼ˆTank|ï¼‰ | æ‰¿ä¼¤|èƒ½åŠ›å¼º || è’™å¤šã€ç›–|ä¼¦ |\n",
            "|| è¾…åŠ©ï¼ˆSupportï¼‰| | ä¿æŠ¤é˜Ÿå‹ã€|æ§åˆ¶æ•Œäºº || é”¤çŸ³ã€ç´¢|æ‹‰å¡ |\n",
            "\n",
            "---\n",
            "\n",
            "##| ğŸ† ç”µç«ä¸|èµ›äº‹ä½“ç³»\n",
            "\n",
            "ã€Š|è‹±é›„è”ç›Ÿã€‹æ‹¥æœ‰|å…¨çƒæœ€æˆç†Ÿçš„ç”µç«ä½“ç³»|ä¹‹ä¸€ï¼š\n",
            "\n",
            "- **èŒä¸š|è”èµ›**ï¼š\n",
            "  -| LPLï¼ˆä¸­å›½ï¼‰\n",
            "|  - LCKï¼ˆéŸ©å›½|ï¼‰\n",
            "  - LCS|ï¼ˆåŒ—ç¾ï¼‰\n",
            "  -LEC|ï¼ˆæ¬§æ´²ï¼‰\n",
            "\n",
            "- **å…¨çƒ|æ€»å†³èµ›**ï¼ˆWorld|sï¼‰ï¼š\n",
            " | - æ¯å¹´ä¸¾è¡Œ|ä¸€æ¬¡ï¼Œæ˜¯ç”µç«|ç•Œæœ€å—ç©ç›®çš„èµ›äº‹|ä¹‹ä¸€ã€‚\n",
            "  - ä¸­å›½|æˆ˜é˜Ÿæ›¾å¤šæ¬¡å¤ºå† |ï¼Œå¦‚ï¼šIG|ï¼ˆ201|8ï¼‰ã€FPX|ï¼ˆ2019ï¼‰ã€|EDGï¼ˆ2|021ï¼‰\n",
            "\n",
            "|- **å­£ä¸­|é‚€è¯·èµ›**ï¼ˆMSI|ï¼‰ï¼š\n",
            "  -| æ¯å¹´æ˜¥å­£|ä¸¾è¡Œï¼Œå„å›½è”èµ›|å† å†›å‚èµ›ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "##| ğŸ¨| æ¸¸æˆæ–‡åŒ–ä¸è¡ç”Ÿ|ä½œå“\n",
            "\n",
            "- **IP|æ‰©å±•**ï¼š\n",
            " | - åŠ¨ç”»å‰§|é›†ã€ŠåŒåŸä¹‹æˆ˜ã€‹|ï¼ˆArcaneï¼‰ï¼š|è®²è¿°çš®å°”ç‰¹|æ²ƒå¤«ä¸ç¥–|å®‰çš„æ•…äº‹ï¼Œå¹¿|å—å¥½è¯„ã€‚\n",
            "  -| æ‰‹æ¸¸ã€Šè‹±é›„è”ç›Ÿï¼š|æ¿€æ–—å³¡è°·ã€‹ï¼ˆWild| Riftï¼‰\n",
            "  -| å¡ç‰Œæ¸¸æˆã€Šç¬¦|æ–‡ä¹‹åœ°ä¼ è¯´ã€‹ï¼ˆLeg|ends of Runet|erraï¼‰\n",
            "  -| ç­–ç•¥æ¸¸æˆ|ã€Šç ´è´¥ç‹è€…ï¼š|è‹±é›„ä¹‹ä¹¦ã€‹\n",
            "\n",
            "|- **éŸ³ä¹ä¸çš®è‚¤**|ï¼š\n",
            "  -| æ¸¸æˆä¸­æœ‰å¤§é‡åŸåˆ›|éŸ³ä¹å’Œè”åŠ¨çš®è‚¤|ï¼ˆå¦‚K/|DAã€çœŸå®ä¼¤å®³|ç­‰è™šæ‹Ÿå¶åƒå›¢ä½“|ï¼‰\n",
            "\n",
            "---\n",
            "\n",
            "##| ğŸ§© æ–°æ‰‹å»ºè®®\n",
            "\n",
            "|1. **é€‰æ‹©|é€‚åˆçš„è‹±é›„**ï¼š|ä»ç®€å•è‹±é›„å¼€å§‹ï¼Œ|å¦‚ç›–ä¼¦ï¼ˆå¦å…‹|ï¼‰ã€å®‰å¦®ï¼ˆæ³•å¸ˆ|ï¼‰ã€è–‡æ©ï¼ˆå°„æ‰‹|ï¼‰ã€‚\n",
            "2. **å­¦ä¹ |åŸºæœ¬æ“ä½œ**ï¼šè¡¥|åˆ€ã€è§†é‡æ§åˆ¶ã€åœ°å›¾|æ„è¯†ã€‚\n",
            "3. **è§‚çœ‹|æ•™å­¦è§†é¢‘**ï¼šB|ç«™ã€YouTubeæœ‰å¾ˆå¤š|é«˜è´¨é‡æ•™å­¦ã€‚\n",
            "4. **|å¤šæ‰“ç»ƒä¹ æ¨¡å¼|**ï¼šç†Ÿæ‚‰æŠ€èƒ½|å’Œèµ°ä½ã€‚\n",
            "5|. **åŠ å…¥é˜Ÿä¼|æˆ–ç¤¾ç¾¤**ï¼šæ›´å®¹æ˜“|ä¸Šæ‰‹ï¼Œè·å¾—|å¸®åŠ©ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "å¦‚æœä½ |æœ‰å…´è¶£ï¼Œæˆ‘å¯ä»¥ä¸ºä½ |æ¨èé€‚åˆä½ çš„è‹±é›„ã€|æ‰“æ³•é£æ ¼ï¼Œæˆ–è€…å¸®ä½ |äº†è§£æŸä¸ªè‹±é›„çš„ç©æ³•|ï¼ä½ æƒ³äº†è§£å“ª|æ–¹é¢çš„å†…å®¹å‘¢ï¼Ÿ|ğŸ®||"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
        "input_message = HumanMessage(content=\"ä¸ºæˆ‘ä»‹ç»lol\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node \n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        data = event[\"data\"]\n",
        "        print(data[\"chunk\"].content, end=\"|\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
      "metadata": {},
      "source": [
        "### ä½¿ç”¨ LangGraph API è¿›è¡Œæµå¼ä¼ è¾“ï¼ˆStreaming with LangGraph APIï¼‰\n",
        "\n",
        "**âš ï¸ DISCLAIMER**\n",
        "\n",
        "**âš ï¸ å…è´£å£°æ˜**\n",
        "\n",
        "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
        "\n",
        "è‡ªä»è¿™äº›è§†é¢‘çš„æ‹æ‘„ä»¥æ¥ï¼Œæˆ‘ä»¬å·²ç»æ›´æ–°äº† Studioï¼Œä½¿å…¶å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ã€‚è¿™æ˜¯ç°åœ¨è¿è¡Œ Studio çš„é¦–é€‰æ–¹å¼ï¼ˆè€Œä¸æ˜¯åƒè§†é¢‘ä¸­æ‰€ç¤ºä½¿ç”¨æ¡Œé¢åº”ç”¨ç¨‹åºï¼‰ã€‚è¯·å‚é˜…æœ‰å…³ [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) æœ¬åœ°å¼€å‘æœåŠ¡å™¨çš„æ–‡æ¡£å’Œ [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server)ã€‚è¦å¯åŠ¨æœ¬åœ°å¼€å‘æœåŠ¡å™¨ï¼Œè¯·åœ¨æœ¬æ¨¡å—çš„ `/studio` ç›®å½•ä¸­çš„ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n",
        "\n",
        "```\n",
        "langgraph dev\n",
        "```\n",
        "\n",
        "You should see the following output:\n",
        "```\n",
        "- ğŸš€ API: http://127.0.0.1:2024\n",
        "- ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
        "- ğŸ“š API Docs: http://127.0.0.1:2024/docs\n",
        "```\n",
        "\n",
        "ä½ åº”è¯¥çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š  \n",
        "```\n",
        "- ğŸš€ API: http://127.0.0.1:2024\n",
        "- ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
        "- ğŸ“š API Docs: http://127.0.0.1:2024/docs\n",
        "```\n",
        "\n",
        "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
        "\n",
        "æ‰“å¼€æ‚¨çš„æµè§ˆå™¨å¹¶å¯¼èˆªåˆ° Studio UIï¼š`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`ã€‚\n",
        "\n",
        "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). \n",
        "\n",
        "LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "079c2ad6",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_client' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# è¿™æ˜¯æœ¬åœ°å¼€å‘æœåŠ¡å™¨çš„åœ°å€\u001b[39;00m\n\u001b[32m      2\u001b[39m URL = \u001b[33m\"\u001b[39m\u001b[33mhttp://127.0.0.1:2024\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m client = \u001b[43mget_client\u001b[49m(url=URL)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# æœç´¢æ‰€æœ‰å·²æ‰˜ç®¡çš„å›¾ï¼ˆassistantsï¼‰\u001b[39;00m\n\u001b[32m      6\u001b[39m assistants = \u001b[38;5;28;01mawait\u001b[39;00m client.assistants.search()\n",
            "\u001b[31mNameError\u001b[39m: name 'get_client' is not defined"
          ]
        }
      ],
      "source": [
        "# è¿™æ˜¯æœ¬åœ°å¼€å‘æœåŠ¡å™¨çš„åœ°å€\n",
        "URL = \"http://127.0.0.1:2024\"\n",
        "client = get_client(url=URL)\n",
        "\n",
        "# æœç´¢æ‰€æœ‰å·²æ‰˜ç®¡çš„å›¾ï¼ˆassistantsï¼‰\n",
        "assistants = await client.assistants.search()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
      "metadata": {},
      "source": [
        "Let's [stream PROTECTED$11$](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before.\n",
        "\n",
        "è®©æˆ‘ä»¬ [stream PROTECTED$11$](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/)ï¼Œåƒä¹‹å‰ä¸€æ ·ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "# Input message\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"], \n",
        "                                      assistant_id=\"agent\", \n",
        "                                      input={\"messages\": [input_message]}, \n",
        "                                      stream_mode=\"values\"):\n",
        "    print(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
      "metadata": {},
      "source": [
        "The streamed objects have: \n",
        "\n",
        "æµå¼ä¼ è¾“çš„å¯¹è±¡å…·æœ‰ï¼š\n",
        "\n",
        "* `event`: Type\n",
        "* `data`: State\n",
        "\n",
        "*`event`: ç±»å‹* `data`: çŠ¶æ€\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "57b735aa-139c-45a3-a850-63519c0004f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================\n",
            "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} id='f51807de-6b99-4da4-a798-26cf59d16412'\n",
            "=========================\n",
            "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-fa4ab1c6-274d-4be5-8c4a-a6411c7c35cc' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'type': 'tool_call'}]\n",
            "=========================\n",
            "content='6' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {}, 'status': 'success'} name='multiply' id='3e7bbfb6-aa82-453a-969c-9c753fbd1d74' tool_call_id='call_imZHAw7kvMR2ZeKaQVSlj25C'\n",
            "=========================\n",
            "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-e8e0d672-cfb2-42be-850a-345df3718f69'\n",
            "=========================\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
        "    messages = event.data.get('messages',None)\n",
        "    if messages:\n",
        "        print(convert_to_messages(messages)[-1])\n",
        "    print('='*25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a555d186-27be-4ddf-934c-895a3105035d",
      "metadata": {},
      "source": [
        "There are some new streaming mode that are only supported via the API.\n",
        "For example, we can [use PROTECTED$11$ mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
        "\n",
        "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ [use PROTECTED$11$ mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) æ¥æ›´å¥½åœ°å¤„ç†ä¸Šè¿°æƒ…å†µï¼\n",
        "\n",
        "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
        "\n",
        "è¿™ç§æ¨¡å¼ç›®å‰å‡è®¾ä½ çš„å›¾å½¢ä¸­æœ‰ä¸€ä¸ª `messages` é”®ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ã€‚\n",
        "\n",
        "All events emitted using `messages` mode have two attributes:\n",
        "\n",
        "æ‰€æœ‰ä½¿ç”¨ `messages` æ¨¡å¼å‘å‡ºçš„äº‹ä»¶éƒ½æœ‰ä¸¤ä¸ªå±æ€§ï¼š\n",
        "\n",
        "* `event`: This is the name of the event\n",
        "* `data`: This is data associated with the event\n",
        "\n",
        "*`event`ï¼šè¿™æ˜¯äº‹ä»¶çš„åç§°* `data`ï¼šè¿™æ˜¯ä¸äº‹ä»¶ç›¸å…³è”çš„æ•°æ®\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metadata\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/complete\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/complete\n"
          ]
        }
      ],
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"], \n",
        "                                      assistant_id=\"agent\", \n",
        "                                      input={\"messages\": [input_message]}, \n",
        "                                      stream_mode=\"messages\"):\n",
        "    print(event.event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
      "metadata": {},
      "source": [
        "We can see a few events: \n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‡ ä¸ªäº‹ä»¶ï¼š\n",
        "\n",
        "* `metadata`: metadata about the run\n",
        "* `messages/complete`: fully formed message \n",
        "* `messages/partial`: chat model tokens\n",
        "\n",
        "*`metadata`: å…³äºè¿è¡Œçš„å…ƒæ•°æ®* `messages/complete`: å®Œæ•´çš„æ¶ˆæ¯  \n",
        "* `messages/partial`: èŠå¤©æ¨¡å‹ä»¤ç‰Œ\n",
        "\n",
        "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
        "\n",
        "ä½ å¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶ [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages) ç±»å‹ã€‚\n",
        "\n",
        "Now, let's show how to stream these messages. \n",
        "\n",
        "ç°åœ¨ï¼Œè®©æˆ‘ä»¬å±•ç¤ºå¦‚ä½•æµå¼ä¼ è¾“è¿™äº›æ¶ˆæ¯ã€‚\n",
        "\n",
        "We'll define a helper function for better formatting of the tool calls in messages.\n",
        "\n",
        "æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ ¼å¼åŒ–æ¶ˆæ¯ä¸­å·¥å…·è°ƒç”¨çš„æ ¼å¼ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
            "Response Metadata: Finish Reason - tool_calls\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "AI: The\n",
            "--------------------------------------------------\n",
            "AI: The result\n",
            "--------------------------------------------------\n",
            "AI: The result of\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying \n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and \n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is \n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is 6\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is 6.\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is 6.\n",
            "Response Metadata: Finish Reason - stop\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "\n",
        "def format_tool_calls(tool_calls):\n",
        "    \"\"\"\n",
        "    Format a list of tool calls into a readable string.\n",
        "\n",
        "    Args:\n",
        "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
        "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if tool_calls:\n",
        "        formatted_calls = []\n",
        "        for call in tool_calls:\n",
        "            formatted_calls.append(\n",
        "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
        "            )\n",
        "        return \"\\n\".join(formatted_calls)\n",
        "    return \"No tool calls\"\n",
        "\n",
        "async for event in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input={\"messages\": [input_message]},\n",
        "    stream_mode=\"messages\",):\n",
        "    \n",
        "    # Handle metadata events\n",
        "    if event.event == \"metadata\":\n",
        "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
        "        print(\"-\" * 50)\n",
        "    \n",
        "    # Handle partial message events\n",
        "    elif event.event == \"messages/partial\":\n",
        "        for data_item in event.data:\n",
        "            # Process user messages\n",
        "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
        "                print(f\"Human: {data_item['content']}\")\n",
        "            else:\n",
        "                # Extract relevant data from the event\n",
        "                tool_calls = data_item.get(\"tool_calls\", [])\n",
        "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
        "                content = data_item.get(\"content\", \"\")\n",
        "                response_metadata = data_item.get(\"response_metadata\", {})\n",
        "\n",
        "                if content:\n",
        "                    print(f\"AI: {content}\")\n",
        "\n",
        "                if tool_calls:\n",
        "                    print(\"Tool Calls:\")\n",
        "                    print(format_tool_calls(tool_calls))\n",
        "\n",
        "                if invalid_tool_calls:\n",
        "                    print(\"Invalid Tool Calls:\")\n",
        "                    print(format_tool_calls(invalid_tool_calls))\n",
        "\n",
        "                if response_metadata:\n",
        "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
        "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
        "                    \n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
