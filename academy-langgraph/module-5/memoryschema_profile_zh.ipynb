{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 带有配置文件模式的聊天机器人（Chatbot with Profile Schema）\n",
        "\n",
        "## 评审（Review）\n",
        "\n",
        "We introduced the [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) as a way to save and retrieve long-term memories.\n",
        "\n",
        "我们介绍了 [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) 作为一种保存和检索长期记忆的方法。\n",
        "\n",
        "We built a simple chatbot that uses both `short-term (within-thread)` and `long-term (across-thread)` memory.\n",
        "\n",
        "我们构建了一个简单的聊天机器人，它同时使用了 `short-term (within-thread)` 和 `long-term (across-thread)` 内存。\n",
        "\n",
        "It saved long-term [semantic memory](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory) (facts about the user) [\"in the hot path\"](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories), as the user is chatting with it.\n",
        "\n",
        "它保存了长期的 [semantic memory](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)（关于用户的事实）[\"in the hot path\"](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories)，当用户与其聊天时。\n",
        "\n",
        "## 目标（Goals）\n",
        "\n",
        "Our chatbot saved memories as a string. In practice, we often want memories to have a structure. \n",
        " \n",
        "For example, memories can be a [single, continuously updated schema]((https://langchain-ai.github.io/langgraph/concepts/memory/#profile)). \n",
        " \n",
        "In our case, we want this to be a single user profile.\n",
        " \n",
        "We'll extend our chatbot to save semantic memories to a single [user profile](https://langchain-ai.github.io/langgraph/concepts/memory/#profile). \n",
        "\n",
        "我们的聊天机器人将记忆保存为字符串。在实际应用中，我们通常希望记忆具有结构。\n",
        "\n",
        "例如，记忆可以是 [single, continuously updated schema]((https://langchain-ai.github.io/langgraph/concepts/memory/#profile))。\n",
        "\n",
        "在我们的例子中，我们希望这是一个单一的用户配置文件。\n",
        "\n",
        "我们将扩展我们的聊天机器人，以将语义记忆保存到单一的 [user profile](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)。\n",
        "\n",
        "We'll also introduce a library, [Trustcall](https://github.com/hinthornw/trustcall), to update this schema with new information. \n",
        "\n",
        "我们还将介绍一个库 [Trustcall](https://github.com/hinthornw/trustcall)，用于使用新信息更新此模式。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain_openai langgraph trustcall langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    # 检查环境变量是否已在操作系统中设置\n",
        "    env_value = os.environ.get(var)\n",
        "    if not env_value:\n",
        "        # 如果未设置，则提示用户输入\n",
        "        env_value = getpass.getpass(f\"{var}: \")\n",
        "    \n",
        "    # 为当前进程设置环境变量\n",
        "    os.environ[var] = env_value\n",
        "\n",
        "_set_env(\"LANGSMITH_API_KEY\")  # 设置LangSmith API密钥\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # 启用LangSmith追踪\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"  # 设置LangSmith项目名称"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 定义用户配置文件模式（Defining a user profile schema）\n",
        "\n",
        "Python has many different types for [structured data](https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition), such as TypedDict, Dictionaries, JSON, and [Pydantic](https://docs.pydantic.dev/latest/). \n",
        "\n",
        "Python 有许多不同类型的 [structured data](https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition)，例如 TypedDict、字典、JSON 和 [Pydantic](https://docs.pydantic.dev/latest/)。\n",
        "\n",
        "Let's start by using TypedDict to define a user profile schema.\n",
        "\n",
        "让我们先使用 TypedDict 来定义一个用户资料模式。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "\n",
        "class UserProfile(TypedDict):\n",
        "    \"\"\"带有类型字段的用户档案模式\"\"\"\n",
        "    user_name: str  # 用户的首选名称\n",
        "    interests: List[str]  # 用户兴趣列表"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 将模式保存到存储中（Saving a schema to the store）\n",
        "\n",
        "The [LangGraph Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) accepts any Python dictionary as the `value`. \n",
        "\n",
        "[LangGraph Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) 接受任何 Python 字典作为 `value`。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['骑行', '科技', '咖啡']}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TypedDict 实例\n",
        "user_profile: UserProfile = {\n",
        "    \"user_name\": \"Lance\",  # 用户名\n",
        "    \"interests\": [\"骑行\", \"科技\", \"咖啡\"]  # 兴趣爱好\n",
        "}\n",
        "user_profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the [put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) method to save the TypedDict to the store.\n",
        "\n",
        "我们使用 [put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) 方法将 TypedDict 保存到存储中。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "# 初始化内存存储\n",
        "in_memory_store = InMemoryStore()\n",
        "\n",
        "# 为要保存的记忆创建命名空间\n",
        "user_id = \"1\"\n",
        "namespace_for_memory = (user_id, \"memory\")\n",
        "\n",
        "# 将记忆以键值对的形式保存到命名空间中\n",
        "key = \"user_profile\"\n",
        "value = user_profile\n",
        "in_memory_store.put(namespace_for_memory, key, value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use [search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) to retrieve objects from the store by namespace.\n",
        "\n",
        "我们使用 [search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) 按命名空间从存储中检索对象。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Lance', 'interests': ['骑行', '科技', '咖啡']}, 'created_at': '2025-07-26T02:04:08.614489+00:00', 'updated_at': '2025-07-26T02:04:08.614494+00:00', 'score': None}\n"
          ]
        }
      ],
      "source": [
        "# Search \n",
        "for m in in_memory_store.search(namespace_for_memory):\n",
        "    print(m.dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use [get](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get) to retrieve a specific object by namespace and key.\n",
        "\n",
        "我们还可以使用 [get](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get) 通过命名空间和键来检索特定对象。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['骑行', '科技', '咖啡']}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the memory by namespace and key\n",
        "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
        "profile.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 带有配置文件模式的聊天机器人（Chatbot with profile schema）\n",
        "\n",
        "Now we know how to specify a schema for the memories and save it to the store.\n",
        "\n",
        "现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。\n",
        "\n",
        "Now, how do we actually *create* memories with this particular schema?\n",
        "\n",
        "现在，我们如何根据这个特定的模式 *创建* 记忆？\n",
        "\n",
        "In our chatbot, we [want to create memories from a user chat](https://langchain-ai.github.io/langgraph/concepts/memory/#profile). \n",
        "\n",
        "在我们的聊天机器人中，我们 [想要从一个聊天里创建记忆](https://langchain-ai.github.io/langgraph/concepts/memory/#profile).\n",
        "\n",
        "This is where the concept of [structured outputs](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) is useful. \n",
        "\n",
        "这就是 [structured outputs格式化输出](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 概念有用的地方。\n",
        "\n",
        "LangChain's [chat model](https://python.langchain.com/docs/concepts/chat_models/) interface has a [PROTECTED$11$](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) method to enforce structured output.\n",
        "\n",
        "LangChain 的 [chat model](https://python.langchain.com/docs/concepts/chat_models/) 接口有一个 [PROTECTED$11$](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 方法用于强制结构化输出。\n",
        "\n",
        "This is useful when we want to enforce that the output conforms to a schema, and it parses the output for us.\n",
        "\n",
        "这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's pass the `UserProfile` schema we created to the `with_structured_output` method.\n",
        "\n",
        "让我们将创建的 `UserProfile` 模式 传递给 `with_structured_output` 方法。\n",
        "\n",
        "We can then invoke the chat model with a list of [messages](https://python.langchain.com/docs/concepts/messages/) and get a structured output that conforms to our schema.\n",
        "\n",
        "然后，我们可以用一组 [messages](https://python.langchain.com/docs/concepts/messages/) 调用聊天模型，并获得符合我们模式的结构化输出。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['骑自行车']}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.chat_models import ChatTongyi\n",
        "# 初始化模型\n",
        "# model = ChatOpenAI(\n",
        "#     model=\"qwen-plus-2025-07-14\",\n",
        "#     api_key=\"sk-ba2dda3817f145d7af141fdf32e31d90\",\n",
        "#     base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
        "# )\n",
        "\n",
        "model=ChatTongyi(\n",
        "    model=\"qwen-plus-2025-07-14\",\n",
        "    api_key=\"sk-ba2dda3817f145d7af141fdf32e31d90\"\n",
        ")\n",
        "\n",
        "# 将模式绑定到模型\n",
        "model_with_structure = model.with_structured_output(UserProfile)\n",
        "\n",
        "# 调用模型生成符合模式的结构化输出\n",
        "structured_output = model_with_structure.invoke([HumanMessage(\"我的名字是Lance，我喜欢骑自行车。\")])\n",
        "structured_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's use this with our chatbot.\n",
        "\n",
        "现在，让我们在聊天机器人中使用它。\n",
        "\n",
        "This only requires minor changes to the `write_memory` function. \n",
        "\n",
        "这只需要对 `write_memory` 函数进行轻微修改。\n",
        "\n",
        "We use `model_with_structure`, as defined above, to produce a profile that matches our schema. \n",
        "\n",
        "我们使用 `model_with_structure`，如上所述，来生成一个与我们模式匹配的配置文件。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.store.base import BaseStore\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "\n",
        "# 聊天机器人指令\n",
        "MODEL_SYSTEM_MESSAGE = \"\"\"你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。\n",
        "如果你有这个用户的记忆，请使用它来个性化你的回复。\n",
        "以下是记忆内容（可能为空）：{memory}\"\"\"\n",
        "\n",
        "# 根据聊天历史和任何现有记忆创建新记忆\n",
        "CREATE_MEMORY_INSTRUCTION = \"\"\"根据用户的聊天历史创建或更新用户档案记忆。\n",
        "这将被保存为长期记忆。如果存在现有记忆，只需更新它。\n",
        "以下是现有记忆（可能为空）：{memory}\"\"\"\n",
        "\n",
        "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"从存储中加载记忆并使用它来个性化聊天机器人的回复。\"\"\"\n",
        "    \n",
        "    # 从配置中获取用户ID\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # 从存储中检索记忆\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    # 为系统提示格式化记忆\n",
        "    if existing_memory and existing_memory.value:\n",
        "        memory_dict = existing_memory.value\n",
        "        formatted_memory = (\n",
        "            f\"姓名: {memory_dict.get('user_name', '未知')}\\n\"\n",
        "            f\"兴趣: {', '.join(memory_dict.get('interests', []))}\"\n",
        "        )\n",
        "    else:\n",
        "        formatted_memory = None\n",
        "\n",
        "    # 在系统提示中格式化记忆\n",
        "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
        "\n",
        "    # 使用记忆以及聊天历史来回复\n",
        "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"反思聊天历史并将记忆保存到存储中。\"\"\"\n",
        "    \n",
        "    # 从配置中获取用户ID\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # 从存储中检索现有记忆\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    # 为系统提示格式化记忆\n",
        "    if existing_memory and existing_memory.value:\n",
        "        memory_dict = existing_memory.value\n",
        "        formatted_memory = (\n",
        "            f\"姓名: {memory_dict.get('user_name', '未知')}\\n\"\n",
        "            f\"兴趣: {', '.join(memory_dict.get('interests', []))}\"\n",
        "        )\n",
        "    else:\n",
        "        formatted_memory = None\n",
        "        \n",
        "    # 在指令中格式化现有记忆\n",
        "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
        "\n",
        "    # 调用模型生成符合模式的结构化输出\n",
        "    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
        "\n",
        "    # 覆盖现有的用户档案记忆\n",
        "    key = \"user_memory\"\n",
        "    store.put(namespace, key, new_memory)\n",
        "\n",
        "# 定义图\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"call_model\", call_model)\n",
        "builder.add_node(\"write_memory\", write_memory)\n",
        "builder.add_edge(START, \"call_model\")\n",
        "builder.add_edge(\"call_model\", \"write_memory\")\n",
        "builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "# 用于长期（跨线程）记忆的存储\n",
        "across_thread_memory = InMemoryStore()\n",
        "\n",
        "# 用于短期（线程内）记忆的检查点\n",
        "within_thread_memory = MemorySaver()\n",
        "\n",
        "# 使用检查点和存储编译图\n",
        "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
        "\n",
        "# 显示\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "你好，Lance！很高兴认识你。旧金山是个骑自行车的绝佳地方，尤其是沿着海滨骑行，风景非常壮观。你有特别喜欢的骑行路线吗？还有，你提到喜欢在面包店吃饭——旧金山有很多出色的面包店，比如Tartine或B.P. Fallon，你有最喜欢的吗？我很乐意听听你的推荐！\n"
          ]
        }
      ],
      "source": [
        "# 我们提供线程ID用于短期（线程内）记忆\n",
        "# 我们提供用户ID用于长期（跨线程）记忆 \n",
        "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
        "\n",
        "# 用户输入 \n",
        "input_messages = [HumanMessage(content=\"你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。\")]\n",
        "\n",
        "# 运行图\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the memory in the store. \n",
        "\n",
        "让我们检查存储中的内存。\n",
        "\n",
        "We can see that the memory is a dictionary that matches our schema.\n",
        "\n",
        "我们可以看到，内存是一个与我们模式匹配的字典。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': 'Lance', 'interests': ['骑自行车', '在面包店吃饭']}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Namespace for the memory to save\n",
        "user_id = \"1\"\n",
        "namespace = (\"memory\", user_id)\n",
        "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
        "existing_memory.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 何时可能会失败？（When can this fail?）\n",
        "\n",
        "[PROTECTED$11$](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) is very useful, but what happens if we're working with a more complex schema? \n",
        "\n",
        "[结构化输出](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 非常有用，但如果我们处理的是更复杂的模式，会发生什么情况？\n",
        "\n",
        "[Here's](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema) an example of a more complex schema, which we'll test below. \n",
        "\n",
        "[这里](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema) 一个更复杂模式的示例，我们将在下面进行测试。\n",
        "\n",
        "This is a [Pydantic](https://docs.pydantic.dev/latest/) model that describes a user's preferences for communication and trust fall.\n",
        "\n",
        "这是一个描述用户沟通和信任偏好的 [Pydantic](https://docs.pydantic.dev/latest/) 模型。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class OutputFormat(BaseModel):\n",
        "    \"\"\"输出格式基类，用于存储用户的偏好信息\"\"\"\n",
        "    preference: str  # 用户的偏好名称\n",
        "    sentence_preference_revealed: str  # 揭示偏好的句子描述\n",
        "\n",
        "class TelegramPreferences(BaseModel):\n",
        "    \"\"\"电报通信偏好设置\"\"\"\n",
        "    preferred_encoding: Optional[List[OutputFormat]] = None  # 偏好的编码方式列表\n",
        "    favorite_telegram_operators: Optional[List[OutputFormat]] = None  # 喜欢的电报操作员列表\n",
        "    preferred_telegram_paper: Optional[List[OutputFormat]] = None  # 偏好的电报纸张类型列表\n",
        "\n",
        "class MorseCode(BaseModel):\n",
        "    \"\"\"摩尔斯电码偏好设置\"\"\"\n",
        "    preferred_key_type: Optional[List[OutputFormat]] = None  # 偏好的按键类型列表\n",
        "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None  # 喜欢的摩尔斯缩写列表\n",
        "\n",
        "class Semaphore(BaseModel):\n",
        "    \"\"\"旗语通信偏好设置\"\"\"\n",
        "    preferred_flag_color: Optional[List[OutputFormat]] = None  # 偏好的旗帜颜色列表\n",
        "    semaphore_skill_level: Optional[List[OutputFormat]] = None  # 旗语技能水平列表\n",
        "\n",
        "class TrustFallPreferences(BaseModel):\n",
        "    \"\"\"信任跌倒游戏偏好设置\"\"\"\n",
        "    preferred_fall_height: Optional[List[OutputFormat]] = None  # 偏好的跌倒高度列表\n",
        "    trust_level: Optional[List[OutputFormat]] = None  # 信任程度列表\n",
        "    preferred_catching_technique: Optional[List[OutputFormat]] = None  # 偏好的接住技巧列表\n",
        "\n",
        "class CommunicationPreferences(BaseModel):\n",
        "    \"\"\"通信偏好设置集合\"\"\"\n",
        "    telegram: TelegramPreferences  # 电报偏好\n",
        "    morse_code: MorseCode  # 摩尔斯电码偏好\n",
        "    semaphore: Semaphore  # 旗语偏好\n",
        "\n",
        "class UserPreferences(BaseModel):\n",
        "    \"\"\"用户偏好设置的完整模型\"\"\"\n",
        "    communication_preferences: CommunicationPreferences  # 通信偏好设置\n",
        "    trust_fall_preferences: TrustFallPreferences  # 信任跌倒游戏偏好设置\n",
        "\n",
        "class TelegramAndTrustFallPreferences(BaseModel):\n",
        "    \"\"\"电报和信任跌倒偏好的综合模型\"\"\"\n",
        "    pertinent_user_preferences: UserPreferences  # 相关的用户偏好设置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's try extraction of this schema using the `with_structured_output` method.\n",
        "\n",
        "现在，让我们尝试使用 `with_structured_output` 方法提取此模式。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "提取的用户偏好：\n",
            "pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=[OutputFormat(preference='摩尔斯电码', sentence_preference_revealed='请用摩尔斯电码。')], favorite_telegram_operators=None, preferred_telegram_paper=[OutputFormat(preference='\"敢死队\"纸张', sentence_preference_revealed='我应该使用我们的\"敢死队\"纸张来发送这条大胆的消息吗？')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='直键', sentence_preference_revealed='我喜欢使用直键。')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='更高的跌落', sentence_preference_revealed='我准备好了更高的跌落')], trust_level=None, preferred_catching_technique=[OutputFormat(preference='钻石队形', sentence_preference_revealed='我更喜欢钻石队形来接住。')]))\n"
          ]
        }
      ],
      "source": [
        "from pydantic import ValidationError\n",
        "\n",
        "# 将模式绑定到模型\n",
        "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
        "\n",
        "# 对话内容\n",
        "conversation = \"\"\"操作员：先生，我如何为您处理电报？\n",
        "客户：我需要发送一条关于我们信任跌倒练习的消息。\n",
        "操作员：当然可以。摩尔斯电码还是标准编码？\n",
        "客户：请用摩尔斯电码。我喜欢使用直键。\n",
        "操作员：很好。您的消息是什么？\n",
        "客户：告诉他我准备好了更高的跌落，并且我更喜欢钻石队形来接住。\n",
        "操作员：完成了。我应该使用我们的\"敢死队\"纸张来发送这条大胆的消息吗？\n",
        "客户：完美！用你最快的信鸽发送。\n",
        "操作员：先生，一小时内就会送达。\"\"\"\n",
        "\n",
        "# 调用模型\n",
        "try:\n",
        "    result=model_with_structure.invoke(f\"\"\"从以下对话中提取偏好信息：\n",
        "    <convo>\n",
        "    {conversation}\n",
        "    </convo>\"\"\")\n",
        "    # 输出结果\n",
        "    print(\"提取的用户偏好：\")\n",
        "    print(result)\n",
        "except ValidationError as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we naively extract more complex schemas, even using high capacity model like `gpt-4o`, it is prone to failure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trustcall 用于创建和更新配置文件模式（Trustcall for creating and updating profile schemas）\n",
        "\n",
        "As we can see, working with schemas can be tricky.\n",
        "\n",
        "正如我们所见，处理模式可能会很棘手。\n",
        "\n",
        "Complex schemas can be difficult to extract. \n",
        "\n",
        "复杂模式可能难以提取。\n",
        "\n",
        "In addition, updating even simple schemas can pose challenges.\n",
        "\n",
        "此外，即使更新简单的模式也可能带来挑战。\n",
        "\n",
        "Consider our above chatbot. \n",
        "\n",
        "考虑我们上面提到的聊天机器人。\n",
        "\n",
        "We regenerated the profile schema *from scratch* each time we chose to save a new memory.\n",
        "This is inefficient, potentially wasting model tokens if the schema contains a lot of information to re-generate each time.\n",
        "\n",
        "这很低效，如果模式包含大量信息，则可能会浪费模型令牌，因为每次都需要重新生成。\n",
        "\n",
        "Worse, we may loose information when regenerating the profile from scratch.\n",
        "\n",
        "更糟的是，当从头重新生成配置文件时，我们可能会丢失信息。\n",
        "\n",
        "Addressing these problems is the motivation for [TrustCall](https://github.com/hinthornw/trustcall)!\n",
        "\n",
        "解决这些问题正是 [TrustCall](https://github.com/hinthornw/trustcall) 的动机！\n",
        "\n",
        "This is an open-source library for updating JSON schemas developed by one [Will Fu-Hinthorn](https://github.com/hinthornw) on the LangChain team.\n",
        "\n",
        "这是一个由 LangChain 团队中的一位 [Will Fu-Hinthorn](https://github.com/hinthornw) 开发的开源库，用于更新 JSON 模式。\n",
        "\n",
        "It's motivated by exactly these challenges while working on memory.\n",
        "\n",
        "它正是出于在研究记忆时所面临的这些挑战而被推动的。\n",
        "\n",
        "Let's first show simple usage of extraction with TrustCall on this list of [messages](https://python.langchain.com/docs/concepts/messages/).\n",
        "\n",
        "\n",
        "让我们首先展示在此 [messages](https://python.langchain.com/docs/concepts/messages/) 列表上使用 TrustCall 进行简单提取的用法。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 对话\n",
        "conversation = [HumanMessage(content=\"嗨，我是兰斯。\"), \n",
        "                AIMessage(content=\"很高兴认识你，兰斯。\"), \n",
        "                HumanMessage(content=\"我非常喜欢在旧金山骑自行车。\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use `create_extractor`, passing in the model as well as our schema as a [tool](https://python.langchain.com/docs/concepts/tools/).\n",
        "\n",
        "我们使用 `create_extractor`，传入模型以及我们的模式作为 [tool](https://python.langchain.com/docs/concepts/tools/)。\n",
        "\n",
        "With TrustCall, can supply supply the schema in various ways. \n",
        "\n",
        "使用 TrustCall 时，可以以多种方式提供模式。\n",
        "\n",
        "For example, we can pass a JSON object / Python dictionary or Pydantic model.\n",
        "\n",
        "例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic 模型。\n",
        "\n",
        "Under the hood, TrustCall uses [tool calling](https://python.langchain.com/docs/concepts/tool_calling/) to produce [structured output](https://python.langchain.com/docs/concepts/structured_outputs/) from an input list of [messages](https://python.langchain.com/docs/concepts/messages/).\n",
        "\n",
        "在底层，TrustCall 使用 [tool calling](https://python.langchain.com/docs/concepts/tool_calling/) 从输入的 [messages](https://python.langchain.com/docs/concepts/messages/) 列表中生成 [structured output](https://python.langchain.com/docs/concepts/structured_outputs/)。\n",
        "\n",
        "To force Trustcall to produce [structured output](https://python.langchain.com/docs/concepts/structured_outputs/), we can include the schema name in the `tool_choice` argument.\n",
        "\n",
        "为了强制 Trustcall 生成 [structured output](https://python.langchain.com/docs/concepts/structured_outputs/)，我们可以在 `tool_choice` 参数中包含模式名称。\n",
        "\n",
        "We can invoke the extractor with  the above conversation.\n",
        "\n",
        "我们可以使用上述对话调用提取器。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 从trustcall导入create_extractor\n",
        "from trustcall import create_extractor\n",
        "# 模式定义\n",
        "class UserProfile(BaseModel):\n",
        "    \"\"\"带类型字段的用户档案模式\"\"\"\n",
        "    user_name: str = Field(description=\"用户的偏好姓名\")\n",
        "    interests: List[str] = Field(description=\"用户兴趣列表\")\n",
        "\n",
        "# 初始化模型\n",
        "model = ChatTongyi(\n",
        "    model=\"qwen-plus-2025-07-14\",\n",
        "    api_key=\"sk-ba2dda3817f145d7af141fdf32e31d90\"\n",
        ")\n",
        "\n",
        "# 创建提取器\n",
        "#tools=[UserProfile] 告诉 LLM 要提取什么结构，而 tool_choice=\"UserProfile\" 强制它只提取这个结构，确保结果精准可控。\n",
        "trustcall_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[UserProfile],\n",
        "    tool_choice=\"UserProfile\"\n",
        ")\n",
        "\n",
        "# 指令\n",
        "system_msg = \"从以下对话中提取用户档案\"\n",
        "\n",
        "# 调用提取器\n",
        "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+conversation})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we invoke the extractor, we get a few things:\n",
        "\n",
        "当我们调用提取器时，我们会得到一些内容：\n",
        "\n",
        "* `messages`: The list of `AIMessages` that contain the tool calls. \n",
        "* `responses`: The resulting parsed tool calls that match our schema.\n",
        "* `response_metadata`: Applicable if updating existing tool calls. It says which of the responses correspond to which of the existing objects.\n",
        "\n",
        "\n",
        "*`messages`：包含工具调用的 `AIMessages` 列表。* `responses`：与我们模式匹配的解析后的工具调用结果。  \n",
        "* `response_metadata`：在更新现有工具调用时适用。它说明哪些响应对应于哪些现有的对象。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UserProfile (call_61393dc3f1154161ba51a9)\n",
            " Call ID: call_61393dc3f1154161ba51a9\n",
            "  Args:\n",
            "    user_name: 兰斯\n",
            "    interests: ['在旧金山骑自行车']\n"
          ]
        }
      ],
      "source": [
        "for m in result[\"messages\"]: \n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[UserProfile(user_name='兰斯', interests=['在旧金山骑自行车'])]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "schema = result[\"responses\"]\n",
        "schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': '兰斯', 'interests': ['在旧金山骑自行车']}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "schema[0].model_dump()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 'call_61393dc3f1154161ba51a9'}]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"response_metadata\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see how we can use it to *update* the profile.\n",
        "\n",
        "让我们看看如何使用它来 *更新* 个人资料。\n",
        "\n",
        "For updating, TrustCall takes a set of messages as well as the existing schema. \n",
        "\n",
        "对于更新，TrustCall 采用一组消息以及现有的模式。\n",
        "\n",
        "The central idea is that it prompts the model to produce a [JSON Patch](https://jsonpatch.com/) to update only the relevant parts of the schema.\n",
        "\n",
        "核心思想是它提示模型生成一个 [JSON Patch](https://jsonpatch.com/)，以仅更新模式的相关部分。\n",
        "\n",
        "This is less error-prone than naively overwriting the entire schema.\n",
        "\n",
        "这比天真地覆盖整个模式更不容易出错。\n",
        "\n",
        "It's also more efficient since the model only needs to generate the parts of the schema that have changed.\n",
        "\n",
        "它也更高效，因为模型只需要生成已更改的模式部分。\n",
        "\n",
        "We can save the existing schema as a dict.\n",
        "\n",
        "我们可以将现有的模式保存为字典。\n",
        "\n",
        "We can use `model_dump()` to serialize a Pydantic model instance into a dict. \n",
        "\n",
        "我们可以使用 `model_dump()` 将 Pydantic 模型实例序列化为字典。\n",
        "\n",
        "We pass it to the `\"existing\"` argument along with the schema name, `UserProfile`. \n",
        "\n",
        "我们将它与模式名称一起传递给 `\"existing\"` 参数，`UserProfile`。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 更新对话\n",
        "updated_conversation = [HumanMessage(content=\"嗨，我是兰斯。\"), \n",
        "                        AIMessage(content=\"很高兴认识你，兰斯。\"), \n",
        "                        HumanMessage(content=\"我非常喜欢在旧金山骑自行车。\"),\n",
        "                        AIMessage(content=\"旧金山是个很棒的城市！骑车后你会去哪里？\"),\n",
        "                        HumanMessage(content=\"骑车后我真的很喜欢去面包店。\")]\n",
        "\n",
        "# 更新指令\n",
        "system_msg = f\"\"\"更新记忆（JSON文档），以整合来自以下对话的新信息\"\"\"\n",
        "\n",
        "# 使用更新的指令和现有档案调用提取器，对应工具名称为UserProfile\n",
        "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+updated_conversation}, \n",
        "                                    {\"existing\": {\"UserProfile\": schema[0].model_dump()}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UserProfile (call_5186b8cfb03e44a3b701b9)\n",
            " Call ID: call_5186b8cfb03e44a3b701b9\n",
            "  Args:\n",
            "    user_name: 兰斯\n",
            "    interests: ['骑自行车', '面包店']\n"
          ]
        }
      ],
      "source": [
        "for m in result[\"messages\"]: \n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 'call_5186b8cfb03e44a3b701b9'}]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"response_metadata\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': '兰斯', 'interests': ['骑自行车', '面包店']}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "updated_schema = result[\"responses\"][0]\n",
        "updated_schema.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LangSmith trace:\n",
        "\n",
        "LangSmith 跟踪：\n",
        "\n",
        "https://smith.langchain.com/public/229eae22-1edb-44c6-93e6-489124a43968/r\n",
        "\n",
        "Now, let's also test Trustcall on the [challenging schema](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema) that we saw earlier.\n",
        "\n",
        "现在，让我们也在之前看到的 [challenging schema](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema) 上测试 Trustcall。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6 validation errors for TelegramAndTrustFallPreferences\n",
            "pertinent_user_preferences.communication_preferences.telegram.preferred_encoding.0\n",
            "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='Morse code', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
            "pertinent_user_preferences.communication_preferences.telegram.favorite_telegram_operators.0\n",
            "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='fastest pigeon', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
            "pertinent_user_preferences.communication_preferences.telegram.preferred_telegram_paper.0\n",
            "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='Daredevils paper', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
            "pertinent_user_preferences.communication_preferences.morse_code.preferred_key_type.0\n",
            "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='hand key', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
            "pertinent_user_preferences.trust_fall_preferences.preferred_fall_height.0\n",
            "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='higher falls', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
            "pertinent_user_preferences.trust_fall_preferences.preferred_catching_technique.0\n",
            "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='diamond formation', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bound = create_extractor(\n",
        "    model,\n",
        "    tools=[TelegramAndTrustFallPreferences]\n",
        ")\n",
        "\n",
        "# 对话\n",
        "conversation = \"\"\"接线员：先生，您的电报有什么需要帮助的吗？\n",
        "客户：我需要发送一条关于我们的信任坠落练习的消息。\n",
        "接线员：当然可以。摩尔斯电码还是标准编码？\n",
        "客户：请用摩尔斯电码。我喜欢使用手键。\n",
        "接线员：很好。您的消息是什么？\n",
        "客户：告诉他我已准备好进行更高的坠落，我更喜欢钻石队形来接住。\n",
        "接线员：完成了。我应该为这条大胆的消息使用我们的\"敢死队\"纸张吗？\n",
        "客户：完美！用你最快的信鸽发送。\n",
        "接线员：先生，一小时内就会送到。\"\"\"\n",
        "\n",
        "result = bound.invoke(\n",
        "    f\"\"\"从以下对话中提取偏好设置：\n",
        "<convo>\n",
        "{conversation}\n",
        "</convo>\"\"\"\n",
        ")\n",
        "\n",
        "# 提取偏好设置\n",
        "result[\"responses\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trace: \n",
        "\n",
        "https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r\n",
        "\n",
        "For more examples, you can see an overview video [here](https://www.youtube.com/watch?v=-H4s0jQi-QY).\n",
        "\n",
        "如需更多示例，您可以查看概述视频 [here](https://www.youtube.com/watch?v=-H4s0jQi-QY)。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 带有配置架构更新的聊天机器人（Chatbot with profile schema updating）\n",
        "\n",
        "Now, let's bring Trustcall into our chatbot to create *and update* a memory profile.\n",
        "\n",
        "现在，让我们将 Trustcall 引入我们的聊天机器人中，以 *创建并更新* 内存配置文件。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAFNAJYDASIAAhEBAxEB/8QAHQABAAMAAwEBAQAAAAAAAAAAAAUGBwIECAMBCf/EAFUQAAEDBAADAgkFCggMBgMAAAEAAgMEBQYRBxIhEzEUFRciQVFWlNMIFjZh0SMyVFV0gZGVstIzcXN1k6GxsxgkJidCQ1JiY3K0wTQ3V4OEhaOk8P/EABsBAQEAAwEBAQAAAAAAAAAAAAABAgMEBQYH/8QANBEAAgADBQUFBwUBAAAAAAAAAAECAxESFCFRkQQxQVLRM2FxkqEFExUiI2KxU8HC4fAy/9oADAMBAAIRAxEAPwD+qaIiAIiIAutWXOjt+vCquCm2NjtpAz+0qAD6vNOZ1PVT22w7LWy055Kit0fvmP744vU4ec/vaWtAL+1R4HjtDsxWShMhJLpZYGySOJ7y57tuJ+sldFiCDCY8cl+/+ZaJbztfOqy/jig95Z9qfOqy/jig95Z9qfNWy/ieg92Z9ifNWy/ieg92Z9ifR7/QuA+dVl/HFB7yz7U+dVl/HFB7yz7U+atl/E9B7sz7E+atl/E9B7sz7E+j3+gwHzqsv44oPeWfanzqsv44oPeWfanzVsv4noPdmfYnzVsv4noPdmfYn0e/0GAGU2UnQu9AT+Us+1d+nqoauPtIJWTR93PG4OH6QugMWsoOxaKDf5Mz7F0Knh7YZJO2paBlprANNq7Z/i0o9I25muYb/wBF2wdnYOylJL4taEwLGigLbca2118Vqu8nhL5ubwS4tjDGz6Gyx4HRsoAJ6ABwBLQNFrZ9ao4HAw8AiIsCBERAEREAVaz6Z77NBbY3mN92qoqAuaSCI3ncuiOoPZNk0R3HRVlVYzodgyxXA77OhusEkhA3psgdBv8AiHbAk+gAn0LfI7SH/Y8PUq3lkiiZBEyKJjY42NDWsYNBoHcAPQFzRFoIFR8042YZw+yCksd9vBpbtVQioZSw0k9Q5kRfyCSTsmOEbC4EBz+UEg9eivC83fKOF2sebQX/AAOy5cOJDLdFT0lbaraaq0XKLt3HwOtJ8xgbtzuclhaJNh5+9AF6xv5Qdqv/ABryjh46hr4Kq0mnjgqhQVT46iR8ckknO/sezia0MAa5z9P2eUnuUriXH7As4yj5u2a/dveHNkfFTzUc9OKgR/fmF8kbWy8vp5C7Q69ypNsqr1g3yiM7lqMbu1VDltFajbLlRUUlRQxzQRTRyMqJWjUIDnNO3a207CyXCrdll24g8H8gv9o4hV2SW66VAyaqu1PM23UUs9JPCG00IPZ9lzvA7WJpaGAF7+oQG3ZJ8qzBbbimUXaz1dXkNTY6WsllpqS21hYJqcuY6GSVsLmxEvAG3dzTz6LPOV24WcRqHinhdBf6CKqgbNGwTRVVFPTFkpja9zWiZjC9o5wA9oLT6CdFZJw74f3mo+S3n+N+Kp6C+XiXJY4aariMD5Xz1FUIXEOA6Oa6Mhx6FpB7lovAfJ5Mg4b2WnqLFe7BWWyipqKppr3b5KR/asiaHcnOPPaCCOZuwfWgNEREQEJmdsfdcaro4CG1sTPCKSR3+rnj8+N3T0BwGx6Rseld6y3SO92aguMIIirKeOoYD6GvaHD+1cMhujLJYbjcJNllLTyTENGyeVpOgPSTrQHpXwxC1PsWJ2S2y/wlHQwU7tetkbWn+xdG+Tjnhpj+xeBLoiLnIEREAREQBda42+nu1vqaKriE1LUxuiljd3Oa4aI/QV2UVTadUCuWq8yWeeGz3qYNqj5lJWvOmVre5o2egm198z09XN6bDYi+8CeHOUXeput4wXHrpcql3PPV1dthkllOgNucW7J0AOvqVyr7fS3WjlpK2mhq6WVvLJBOwPY8eotPQqA+YVNT9KC63i2x9dRQVznsbv1Nk5w0fUND6lv+nMxbo/T+i4Mrv+DXwn/9N8WP/wBRB+6rrjWL2fDbPDabDa6SzWyEuMdHQwthiYXEudprQANkkn6yov5k1HtVfv6aH4SfMmo9qr9/TQ/CT3cvn9GKLMtCKr/Mmo9qr9/TQ/CVTx633W58QMus02U3jwK1sonU5ZLDz7lY9z+Y9n62jXQJ7uXz+jFFmaoq1mPDTEuIZpDlGNWrITSc/g5udHHP2PNrm5eYHW+Vu9d+h6lw+ZNR7VX7+mh+EnzJqPaq/f00Pwk93L5/RiizK/8A4NnCfWvJvi2vV4pg1+yp/E+GmG8N/DKjHMbs+N9uweEy2+kjp+drdkc5aBsDZPXu2V+jCagEH503469Bmh6//iXKPh9a5JGSXGSsvbmEFrbnUvmjBB2D2RPZ7313y7SxKW+PRdaCiPmZW53UU5g0/HaeVsxn66rZGEOYGegxBwDubucQNbGybUnci1xx2qJYJBsIiLWQIiIAiIgCIiAIiIAiIgCz3DiPLBxFGzvsrZsf+1J9a0JZ7h2/LBxF7tdlbO7W/wCCk/P+lAaEiIgCIiAIiIAiIgCIiAIiIAiIgCIiAIiIAs8w3/zi4jdQfuVr6AdR9ylWhrPMN15YuI3r7K1+j/hSoDQ0REAREQBERAEREAREQBERAEUTkOQMsNNERC6rrKh/ZU1Kw6Mr9E9SejWgAkuPcB6SQDXzfswcdi3WRm/9Hw2Z2vq32Q3+gLogkRzFaW7vdC0LsipHj3MPwCx+9zfDTx7mH4BY/e5vhrZdY81qhQu6KkePcw/ALH73N8NPHuYfgFj97m+Gl1jzWqFC0X+trLbYrlV2+h8aXCnppJaeh7XsvCJGtJZHz6PLzEAb0db3orw5wI+XVV8SPlB1FkoeG88VZk1RS00wN1BNBHA14llcOwHPytLncux97rfXa9d+Pcw/ALH73N8NZBw8+T/Nw34y5hxFttvszrnkIGqZ1RKI6QuPNMWfc/8AWOAPo11A6FLrHmtUKHpZFSPHuYfgFj97m+Gnj3MPwCx+9zfDS6x5rVChd0VI8e5h+AWP3ub4aePcw/ALH73N8NLrHmtUKF3RUjx7mH4BY/e5vhrkzJMppj2lTaLbUwt6vjo6x4lI9PIHxhpPqBLQfWEuszNaoULqi6tsuVNebdT11JJ2tNUMEkbtFpIPrB6g+sHqD0K7S5GmnRkCIigCIiApeYH/ACzxYejs6w/n5Y/tKkVHZh9NMW/kqz9mNSK9RdlL8P5Mr4BERQgRQ+S5dacQjt0l2q/BGXCugttMeze/tKiZ3LGzzQdbPTZ0B6SEteXWm9X+92Sjq+2udldC2vg7N7exMrO0j84gNdtvXzSdenRUBMIiKgIiIAih7bl1pu+R3mw0lX2t1s7YH11P2b29iJmudF5xAa7Ya4+aTrXXS55XlNrwjG7jfr1VeBWm3QuqKqo7N0nZxt6k8rAXH+IAlQEqi4xStniZIw8zHtDmn1grkqDr8LzvDYPqqqwDXoAqpQFa1U+F30Nh/K6z/qpVbFy7T28zxf5K97CIi5iBERAUvMPppi38lWfsxqRUdmH00xb+SrP2Y1Ir1F2Uvw/kyvgZFx9vt0juGAYtb7vU47S5Re/AK27UbgyeOJkEsvZRPI8x8jowwOHUdddVBcSrFHg+PWHDrbes3vt5yC7ONvhZkb4ah3ZwOfKySteC+OBrWl51zPLtAbHRa7mmDWHiJYZLNkdtiuluke2TspSWlr2nbXsc0hzHD0OaQR61Vf8AB4wDxCyz+JZjSsrPGDJjcqo1Tajk7PtBU9r2oPIA3o/qOnctbTIYFQX3ILlgNjtuS1U1XW2Di5QWlklTWeGStiZPE9rHzljDKW9qW85aCQBsLZeF5/z/AHGsentrOdf/AAQp2P5P3D6HGbtj0eNwR2W6zx1VXSNmlDXzsDQ2Zp59sk8xpL2kOcRsknqu3duGtPSXuoybFobfasxlo47c6518U9TFJTtcCGyRMmj7RwDdNeTzD16JBiTQOfG24VVp4M57XUNTNR1tNYK+aCpp5CySKRtPIWva4dWuBAII6ghYfQYrcqjiFwytk2c5jJRZTjlXcLtGL3M3tp4m0zmujLSDB1ndsQ8gPKB3b3sJxLNshgqrTlt5xi641cKeakuFFQWaqpZpoZI3Mc1sprX8m+bv5Sdb1o9RY4sAsMN2sNzZQarrFRyUFul7aT7hBIIw9mubTtiKPq4Ejl6Hqd1qoPNeHZPkueS8O8FueU3iloJ67Ioay60lWYK+4Nt9T2VPEZ26c08rg55bpzuTv71xGb5MZXcN48rubKB+fOxoZS6YOrm0YoxVGnE5H8Pz7hEh24D6+q3q4cC8HumPR2Sosm6CKvmukXZ1U8c0NTK9z5ZI5mvEjC5z3/euA0da10XKXgdgs2BjDH45THHBL4R4LzvD+25ubtu15u07TfXtObm+tY2WDzLlFZeeD2W8UrZjd4uVVVXO54vaRdLxci+emiqGzB5NS9khZ080SOa8s5wdHQCmOImG8RMU4QcVfHtQRis2Lz8lHWZJNe6llYCNPbLLTxOaxzC7bSXDbWkAbK3q0/J+wCzWrILbDjzJ6LII4orpFXVM1V4UIgezLjK9x23mOnAg70d7A12ca4JYXidovNst9m5qK8QCmr466qnrDURBrmiNzpnvdygPeA0HQ5illgt1pIdaqMg7BhZoj/lC7ajMZxu3YfYKGy2mB1NbaGIQ08LpXyljB3DmeS46+slSa2A63C76Gw/ldZ/1UqtiqfC76Gw/ldZ/1Uqti5tp7eZ4v8le9hERcxAiIgKXmH00xb+SrP2Y1Ir6ZXYqi5+BVtCY/GFA9z4o5nFrJmuaWujcR3bGiDo6IHQjooE3S/tOjh1ycR3mOqoy3825gf6gvUltRy4UmsFxaXFvj4mW8mkUJ42v3sZdfeqL46eNr97GXX3qi+Os7H3LzLqKE2ihPG1+9jLr71RfHTxtfvYy6+9UXx0sfcvMuooTaKE8bX72MuvvVF8dR1Fm9fcbzcrTT4pdZK+3CJ1VF29IOzEgJZ1M2jsNPcTrXVLH3LzLqKFsRQnja/exl196ovjp42v3sZdfeqL46WPuXmXUUJtFCeNr97GXX3qi+Onja/exl196ovjpY+5eZdRQm0UJ42v3sZdfeqL465NrMjrPuUOMVFFI7oJq+qp+yZ/vERyPcdeoDr6x3pY+5eZdSUJDhd9DYfyus/6qVWxRuO2VmPWWlt7JHTdi080r+he8kuc76tuJOvrUkvOnRKObFGtzb/Ie8IiLSQIiIAiIgCIiAIiIAs+w8f53uIh1/qrZ11/wpPq/7laCs9w5uuMHEU6PWK2dddD9ykQGhIiIAiIgCIiAIiIAiIgCIiAIiIAiIgCIiALPMNI8sXEbr17K176f8KX0rQ1nuHc3lf4i7LuXsrZoEdP4KTuQGhIiIAiIgCIiAIiIAiIgCIoW8Ztj2P1QprnfLdb6kjm7GpqmMfr18pO9LOGCKN0hVWWlSaRVbypYd7U2j32P7U8qWHe1No99j+1bbvO5Hoy2XkWlFVvKlh3tTaPfY/tTypYd7U2j32P7Uu87kejFl5FpRVbypYd7U2j32P7U8qWHe1No99j+1LvO5HoxZeRYq6uprXQ1FbW1EVJR08bppqid4ZHExo25znHoAACST0ACxrBeK2D1nGTNmU+Y2CeS4eK4KRsd0gcamTs5G8ken+e7mIGgN7IHpV6ufEDBLzbau312RWWqoquF8E8ElZGWyRuBa5pG+4gkLwD8mr5NuP4H8q2+3O93q2uxHFpfCrJVz1UfJWyP605ad6Jjbtztfeva0HvS7zuR6MWXkf0wRVbypYd7U2j32P7U8qWHe1No99j+1LvO5HoxZeRaUVW8qWHe1No99j+1PKlh3tTaPfY/tS7zuR6MWXkWlFVvKlh3tTaPfY/tTypYd7U2j32P7Uu87kejFl5FpRVbypYd7U2j32P7VMWbIrVkUT5bVcqS5RxkB7qSdsgaT3A8pOvzrGKTMgVYoWl4Eo0SKIi0kOleqx1vs9dVMAL4IJJWg+trSR/YqjiVJHTWCikA5p6mJk88zur5pHNBc9xPUkk/m7u4Kz5V9GLx+RzfsFV7Gvo5avySL9gL0JGEp+JeBJIiLMgREQBERAEREAREQBERAEREAUFfC223ix3KAdnVOroqN729DJFIeUsd6xshw3vRaNKdUDlv31i/nek/vAtsrGKmZVvNBREXjkIvKvoxePyOb9gqvY19HLV+SRfsBWHKvoxePyOb9gqvY19HLV+SRfsBejJ7F+P7F4HZuc9TS22rmo6ZtZWRwvfDTOk7MSvDSWsLtHl2dDejrfcVkuN/KbsGQVfDKjdTSUtZm1HLUNjL+YUEsbesMh5RsmRssYPTboz09C2NeeKr5J0YsHFCnoroILpkFd4bYasOcPFBZIaqFjSBtgFXLO48ne149PRHXgQkY/lK3K7T4lDYsL8auyqtu1Na3OughY+CjcGtqZCYjyskHM7Q2QA3XOXALo5PxHy225nnUXil9uv9twaK6UlOy/me37L5OZ/ZGmAbKyRsrec752xsBDebpb6fg1JZMn4TS2iSmjseF2+soJI5XOE0gkp4ooywBpBO4yXbI7/Svvf+FFZkPFDJL5NVU8Nnu+IMxzTC41DJe3qHufy8vLy8szdedvYPQd6x+YFNtvyhLng/A7D8gza32+K93qOkprc116jjirnPpmyGonmkjjZTggPc4aeB0ALi4BW7gtx3oeL1bfrY2Ggp7tZuwfUC03aK50kkcodyOjqIwATuN4LS1pBA6aIKpbOCnEGswTC6OrrMap8mwWandZKmEzy0tdEyB0EjKprmNMfaRkfec3Ke5aDa8pu+CWSSsz6joaepqans6eDD7bXXFrIwwHUhZCXk7DzzFjW9QO/qSrxBLcW+ITeFXDy8ZU+3vujLc2N5pI5RG6QOlYzQcQQCObfXv1rY71QZON+dtzOtxJvDKB9/htrbzFGMiZ2ElKXuj0ZOw22bnbyhga5veecDRP24lXOj4/cPMgwvGjcKW7VsEb45b3ZLhQUwDJo3HcstOBvQ6AbJ9WgSLYzA7g3jpNmhmpvFb8bjs4h5ndv2zap8pdrl5eTlcBvm3v0elV1bwBnl7+V5YYLNh9RaoLc64ZHaxeGQZBe4LTBS0++Xz5pA7meX8zQ1jXb5HE6A2vraPlSHLqTEmYzjDLxdb9WXC3GnN2ibBTVFI0OfuoY17ZIi0lwkZvY5dNJOhB4f8nfNeG1twS52Kqx2vyWz4/8AN260F0dN4DVQiZ0zHxStjL2PY9zu9hBDiOmtrQpOHeS3fMOGWQ3SSyxVOPG4vucVuEjI3meAxxiBrgSddNlxb3Ej1LH5gVSg+U3ezbJrxdMANtsdtvox28VTbwyaSkqjUNg544xGO1iD5IwXEsd5x0062ZHJPlGV9rlyy5WrC571h2J1T6O83ltwZFK18Qa6oMFOWkyiIO84l7NlrgN6XVuvAi/13DLOccjrLaK2+5h84KaR0snZsp/GEFTyvPJsP5InDQBGyOuuo6uS8EM6NFnuKY7dLDBh2aV1RWVdXXCbw+gFU0CrZFG1vZyh3nlpc5nLzne9BPmBZqTjTfcl4jZDi+L4hBdqWy+Ayz3equ3g0L4qmFsrS1ohe4vAJ83uIbsuaSAf2ycfo8gx3h3WUdkc67ZZcHW+W1PqdOt7oWyGsc53J5/YmFzdabzEt+92pThvwxqcEzrNrmJKc2m7ttsVBEx7nSxspqUQESbaACSOmidjv13LNeBeK0eQ8ds8ze01UtbhsMr22QuhcyHwyqbE64yQlwHMC+CMcw2NvkAPeriD0goHLfvrF/O9J/eBTygct++sX870n94F0yv+0VbzQURF45CLyr6MXj8jm/YKr2NfRy1fkkX7AVpvNG642iupGEB88EkQJ9Bc0j/uqhiVZHUWGjhB5KmmhZBUQO6Phka0BzHA9QQf0jRHQhehIxlNd5eBMIiLMgREQBERAEREAREQBERAEREAUDlv31i/nek/vAp5QV75bpebJbaciWqZXRVkrGdTFFGeYvd6gSA0b1snotsrCKuRVvNAREXjkChbxhWP5DUCouljttxnA5RLVUkcjwPVtwJ0ppFlDHFA6wujG4q3krwz2Tsn6vi/dTyV4Z7J2T9Xxfuq0ot14nc71ZavMq3krwz2Tsn6vi/dTyV4Z7J2T9Xxfuq0ol4nc71Yq8yreSvDPZOyfq+L91PJXhnsnZP1fF+6rSiXidzvVirzKt5K8M9k7J+r4v3VRsU4d4vUcVM8pJcetUtLTR24wU76OIsh5opC7lbrzeYgb6DelsSz3DifK/xFBOwIrZoden3KT8yXidzvVirzJnyV4Z7J2T9Xxfup5K8M9k7J+r4v3VaUS8Tud6sVeZVvJXhnsnZP1fF+6nkrwz2Tsn6vi/dVpRLxO53qxV5lW8leGeydk/V8X7qeSvDPZOyfq+L91WlEvE7nerFXmVbyV4Z7J2T9XxfuqZs+P2vHoHQ2q20ltieduZSQNiDj6yGgbUgixinTI1SKJteIqwiItJAiIgCIiAIiIAiIgCz3DgRxg4inl0DFbPO69fuUi0JZ5hrSOMPEY8pAMVr6nuP3KRAaGiIgCIiAIiIAiIgCIiAIiIAiIgCIiAIiIAs9w4DywcRTob7K2d29/wAFJ+b9CvF1bWutlYLa+CO4mF4pn1THPhbLynkL2tIJbza2AQdb0QvA3ycvlLcY+IHypLxi9wx3HLfUSzMZkZbR1INJDSczHdnuchrnF3KC7mHM5p1pAf0DREQBERAEREAREQBERAEREAREQHSvN5o8ftk9wuE7aakgbzPkcCfqAAHUknQAGySQACSsbvvGa/XWRzbPBBZaTubJUs7epcPXrfIz+Lz/AOMdy6fFHJJMjzCeja/dutDxDEwHo6oLfukh+sB3Zj1ak/2lVl9p7O9mS4ZamzlVvGj3L/d4boTDs8zF2v8AKqqafTy0dJr+uEr8+fWZe1lZ7pSfBUQi9u67P+lD5V0JaZL/AD6zL2srPdKT4KrFjt1XjeZX7K7bdZqTIL6Im3GuZS0pdOIxpvQxab9fKBzHqdnqpBEu2z/pQ+VdBaZL/PrMvays90pPgp8+sy9rKz3Sk+CqdleW0eHUdHU1sc8sdVXU9AwQNBIkmkEbCdkeaC4b9OvQVNKXfZm6e7h8q6C0yZZn+ZREEZPPKQd6mo6Yg/UeWNp/rVxxfjZPHOymyangiicdC50Yc2Nh9HaRkksHreHEDvIaASs1RaZ2wbNOhsuBLwSX4FrM9StcHAEEEHqCPSv1ZRwPyWRzKzG538zaNjaii2dlsBOnR/xMdrXqD2tGg0LV18DtWzxbLNilRcDIIiLlIEREAREQBERAeXKvm8dXwP32gutaH7Pp8Ik/q1rX1aXBXLizi0thyaW8RMJtl0c0yPHdDUgBuj6g8BpB/wBoO9Lm7zrILVWXeiZDQ3mrscrZA81FHHDI9zdEchEsb266g9BvoOvfv9N2edDOkQzIMcPXiiRbyTVT4tXC6WrhllFZZOfxrBb5n07oht7XBp85v1gbI+sL5NwnIAHA8Qb4djQJo7f0694/xb/+2u5ZsWvFtuMVRV5jdbtAzfNSVVNRsjfsEDZjga7oTvo4d3Xp0WyJxRpw2Wq8cMPUhiOJ4RTQQ0l6tGU47yvtVTPPTWiGZlRconQEEz89VJzFr3McXFuw4a2N6XYwywUWM0vBC82uDsLpdqdsFfP2ji6ra+3vk5ZCSeYB7GloP3ugBodFuVvwrHrTUVU9DYbZRT1QLaiSno443TA94eQ3bgfTtdpmP2uOK3RsttI2O3a8CY2BoFLppYOyGvM80lvm66HXcuSHY1DSlFTqugPLtFQY7dsFw7JqyeKqz2ryeh8YzT1B8KbN4aA+Es5vNawDQZrQDQdelesVBy4JjU90fcpMetUlxfI2V1Y+iiMzntIc1xfy72CAQd9CAop+E5A5xI4g3xoJ2Gijt+h/+ss5MqLZ64VrTd3cXXiwXFFTn4TkDnEjiDfGgnfKKO36H1f+GVqpY3UNBCyoqn1L4Yg2SqnDWukIHV7uUBoJ1s6AHqAC7IYnFvhpp1IXHhGXHiVThhPS21Jf16cvaQf99foK3xZnwXxOa3UtXfa2Iw1Fe1sdPG8acynbsgkHuL3EnXqDO47C0xfBe1ZsM3anY3LA2PIIiLxyBERAEREAREQHwrqGnudHNSVcEdTTTNLJIpWhzXtPeCCslv3A6sgldJj1yifATsUd0LjyfU2Zu3a/5muP+8thRdmzbXO2V1lRUrw4FMBPCfMm9PArY4+ktr3a/NuIf2L88lGZfgNt9/d8Nb+i9P41tOS0/sYZGAeSjMvwG2+/u+GnkozL8Btvv7vhrf0T41tOS0fUYZGAeSjMvwG2+/u+GnkozL8Btvv7vhrf0T41tOS0fUYZGBM4SZlKQBTWmL1ulr36H6Ijv+pXHE+C9PbqmKsvtW27VEZDmUscfJTMcDsEtJJeR6NnXp5d6K0xFone1tqnQ2a0XcK5BEReOQIiIAiIgP/Z",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.store.base import BaseStore\n",
        "\n",
        "# Initialize the model\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Schema \n",
        "class UserProfile(BaseModel):\n",
        "    \"\"\" Profile of a user \"\"\"\n",
        "    user_name: str = Field(description=\"The user's preferred name\")\n",
        "    user_location: str = Field(description=\"The user's location\")\n",
        "    interests: list = Field(description=\"A list of the user's interests\")\n",
        "\n",
        "# Create the extractor\n",
        "trustcall_extractor = create_extractor(\n",
        "    model,\n",
        "    tools=[UserProfile],\n",
        "    tool_choice=\"UserProfile\", # Enforces use of the UserProfile tool\n",
        ")\n",
        "\n",
        "# Chatbot instruction\n",
        "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
        "If you have memory for this user, use it to personalize your responses.\n",
        "Here is the memory (it may be empty): {memory}\"\"\"\n",
        "\n",
        "# Extraction instruction\n",
        "TRUSTCALL_INSTRUCTION = \"\"\"Create or update the memory (JSON doc) to incorporate information from the following conversation:\"\"\"\n",
        "\n",
        "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
        "    \n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve memory from the store\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    # Format the memories for the system prompt\n",
        "    if existing_memory and existing_memory.value:\n",
        "        memory_dict = existing_memory.value\n",
        "        formatted_memory = (\n",
        "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
        "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
        "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"      \n",
        "        )\n",
        "    else:\n",
        "        formatted_memory = None\n",
        "\n",
        "    # Format the memory in the system prompt\n",
        "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
        "\n",
        "    # Respond using memory as well as the chat history\n",
        "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
        "    \n",
        "    # Get the user ID from the config\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # Retrieve existing memory from the store\n",
        "    namespace = (\"memory\", user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "        \n",
        "    # Get the profile as the value from the list, and convert it to a JSON doc\n",
        "    existing_profile = {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
        "    \n",
        "    # Invoke the extractor\n",
        "    result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]+state[\"messages\"], \"existing\": existing_profile})\n",
        "    \n",
        "    # Get the updated profile as a JSON object\n",
        "    updated_profile = result[\"responses\"][0].model_dump()\n",
        "\n",
        "    # Save the updated profile\n",
        "    key = \"user_memory\"\n",
        "    store.put(namespace, key, updated_profile)\n",
        "\n",
        "# Define the graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"call_model\", call_model)\n",
        "builder.add_node(\"write_memory\", write_memory)\n",
        "builder.add_edge(START, \"call_model\")\n",
        "builder.add_edge(\"call_model\", \"write_memory\")\n",
        "builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "# Store for long-term (across-thread) memory\n",
        "across_thread_memory = InMemoryStore()\n",
        "\n",
        "# Checkpointer for short-term (within-thread) memory\n",
        "within_thread_memory = MemorySaver()\n",
        "\n",
        "# Compile the graph with the checkpointer fir and store\n",
        "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi, my name is Lance\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, Lance! It's nice to meet you. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "# We supply a thread ID for short-term (within-thread) memory\n",
        "# We supply a user ID for long-term (across-thread) memory \n",
        "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
        "\n",
        "# User input \n",
        "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I like to bike around San Francisco\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That sounds like a great way to explore the city! San Francisco has some beautiful routes and views. Do you have any favorite trails or spots you like to visit while biking?\n"
          ]
        }
      ],
      "source": [
        "# User input \n",
        "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'value': {'user_name': 'Lance',\n",
              "  'user_location': 'San Francisco',\n",
              "  'interests': ['biking']},\n",
              " 'key': 'user_memory',\n",
              " 'namespace': ['memory', '1'],\n",
              " 'created_at': '2024-11-04T23:51:17.662428+00:00',\n",
              " 'updated_at': '2024-11-04T23:51:41.697652+00:00'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Namespace for the memory to save\n",
        "user_id = \"1\"\n",
        "namespace = (\"memory\", user_id)\n",
        "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
        "existing_memory.dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_name': 'Lance',\n",
              " 'user_location': 'San Francisco',\n",
              " 'interests': ['biking']}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The user profile saved as a JSON object\n",
        "existing_memory.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I also enjoy going to bakeries\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Biking and visiting bakeries sounds like a delightful combination! San Francisco has some fantastic bakeries. Do you have any favorites, or are you looking for new recommendations to try out?\n"
          ]
        }
      ],
      "source": [
        "# User input \n",
        "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Continue the conversation in a new thread.\n",
        "\n",
        "在新线程中继续对话。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What bakeries do you recommend for me?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Since you're in San Francisco and enjoy going to bakeries, here are a few recommendations you might like:\n",
            "\n",
            "1. **Tartine Bakery** - Known for its delicious bread and pastries, it's a must-visit for any bakery enthusiast.\n",
            "2. **B. Patisserie** - Offers a delightful selection of French pastries, including their famous kouign-amann.\n",
            "3. **Arsicault Bakery** - Renowned for its croissants, which have been praised as some of the best in the country.\n",
            "4. **Craftsman and Wolves** - Known for their inventive pastries and the \"Rebel Within,\" a savory muffin with a soft-cooked egg inside.\n",
            "5. **Mr. Holmes Bakehouse** - Famous for their cruffins and other creative pastries.\n",
            "\n",
            "These spots should offer a great variety of treats for you to enjoy. Happy bakery hopping!\n"
          ]
        }
      ],
      "source": [
        "# We supply a thread ID for short-term (within-thread) memory\n",
        "# We supply a user ID for long-term (across-thread) memory \n",
        "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
        "\n",
        "# User input \n",
        "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
        "\n",
        "# Run the graph\n",
        "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trace:\n",
        "\n",
        "https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r\n",
        "\n",
        "## 工作室（Studio）\n",
        "\n",
        "![Screenshot 2024-10-30 at 11.26.31 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0437060f1754ea79908_Screenshot%202024-11-11%20at%207.48.53%E2%80%AFPM.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
