{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83fcadf3",
      "metadata": {},
      "source": [
        "[PROTECTED$11$](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/chatbot-summarization.ipynb) [PROTECTED$12$](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239436-lesson-5-chatbot-w-summarizing-messages-and-memory)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
      "metadata": {},
      "source": [
        "# å¸¦æœ‰æ¶ˆæ¯æ€»ç»“åŠŸèƒ½çš„èŠå¤©æœºå™¨äººï¼ˆChatbot with message summarizationï¼‰\n",
        "\n",
        "## è¯„å®¡ï¼ˆReviewï¼‰\n",
        "\n",
        "We've covered how to customize graph state schema and reducer. \n",
        " \n",
        "We've also shown a number of ways to trim or filter messages in graph state. \n",
        "\n",
        "æˆ‘ä»¬å·²ç»ä»‹ç»äº†å¦‚ä½•è‡ªå®šä¹‰å›¾çŠ¶æ€æ¨¡å¼å’Œ reducerã€‚  \n",
        "  \n",
        "æˆ‘ä»¬è¿˜å±•ç¤ºäº†å¤šç§ä¿®å‰ªæˆ–è¿‡æ»¤å›¾çŠ¶æ€ä¸­æ¶ˆæ¯çš„æ–¹æ³•ã€‚\n",
        "\n",
        "## ç›®æ ‡ï¼ˆGoalsï¼‰\n",
        "\n",
        "Now, let's take it one step further! \n",
        "\n",
        "ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ›´è¿›ä¸€æ­¥ï¼\n",
        "\n",
        "Rather than just trimming or filtering messages, we'll show how to use LLMs to produce a running summary of the conversation.\n",
        " \n",
        "This allows us to retain a compressed representation of the full conversation, rather than just removing it with trimming or filtering.\n",
        "\n",
        "ä¸å…¶ä»…ä»…ä¿®å‰ªæˆ–è¿‡æ»¤æ¶ˆæ¯ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥ç”Ÿæˆå¯¹è¯çš„å®æ—¶æ‘˜è¦ã€‚\n",
        "\n",
        "è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿä¿ç•™æ•´ä¸ªå¯¹è¯çš„å‹ç¼©è¡¨ç¤ºï¼Œè€Œä¸ä»…ä»…æ˜¯é€šè¿‡ä¿®å‰ªæˆ–è¿‡æ»¤å°†å…¶ç§»é™¤ã€‚\n",
        "\n",
        "We'll incorporate this summarization into a simple Chatbot.  \n",
        "\n",
        "æˆ‘ä»¬å°†æŠŠè¿™ä¸ªæ‘˜è¦æ•´åˆåˆ°ä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººä¸­ã€‚\n",
        "\n",
        "And we'll equip that Chatbot with memory, supporting long-running conversations without incurring high token cost / latency. \n",
        "\n",
        "æˆ‘ä»¬å°†ä¸ºè¯¥èŠå¤©æœºå™¨äººé…å¤‡è®°å¿†åŠŸèƒ½ï¼Œæ”¯æŒé•¿æ—¶é—´å¯¹è¯ï¼ŒåŒæ—¶ä¸ä¼šäº§ç”Ÿé«˜æ˜‚çš„ token æˆæœ¬æˆ–å»¶è¿Ÿã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_core langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "09201a62",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
      "metadata": {},
      "source": [
        "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing).\n",
        "\n",
        "æˆ‘ä»¬å°†ä½¿ç”¨ [LangSmith](https://docs.smith.langchain.com/) ç”¨äº [tracing](https://docs.smith.langchain.com/concepts/tracing)ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "464856d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "_set_env(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model =ChatOpenAI(\n",
        "    model=\"qwen-plus-2025-04-28\",\n",
        "    api_key=\"sk-ba2dda3817f145d7af141fdf32e31d90\",\n",
        "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
      "metadata": {},
      "source": [
        "We'll use `MessagesState`, as before.\n",
        "\n",
        "æˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨ `MessagesState`ã€‚\n",
        "\n",
        "In addition to the built-in `messages` key, we'll now include a custom key (`summary`).\n",
        "\n",
        "é™¤äº†å†…ç½®çš„ `messages` é”®ä¹‹å¤–ï¼Œæˆ‘ä»¬ç°åœ¨è¿˜å°†åŒ…å«ä¸€ä¸ªè‡ªå®šä¹‰é”®ï¼ˆ`summary`ï¼‰ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState\n",
        "class State(MessagesState):\n",
        "    summary: str"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
      "metadata": {},
      "source": [
        "We'll define a node to call our LLM that incorporates a summary, if it exists, into the prompt.\n",
        "\n",
        "æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹æ¥è°ƒç”¨æˆ‘ä»¬çš„LLMï¼Œå¦‚æœå­˜åœ¨æ‘˜è¦ï¼Œåˆ™å°†å…¶çº³å…¥æç¤ºä¸­ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage \n",
        " \n",
        " # å®šä¹‰è°ƒç”¨æ¨¡å‹çš„é€»è¾‘\n",
        "def call_model(state: State): \n",
        "     \n",
        "     # è·å–æ‘˜è¦ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ \n",
        "     summary = state.get(\"summary\", \"\") \n",
        " \n",
        "     # å¦‚æœæœ‰æ‘˜è¦ï¼Œåˆ™æ·»åŠ å®ƒ\n",
        "     if summary: \n",
        "         \n",
        "         # å°†æ‘˜è¦æ·»åŠ åˆ°ç³»ç»Ÿæ¶ˆæ¯ä¸­\n",
        "         system_message = f\"å…ˆå‰å¯¹è¯çš„æ‘˜è¦ï¼š{summary}\" \n",
        " \n",
        "         # å°†æ‘˜è¦é™„åŠ åˆ°ä»»ä½•è¾ƒæ–°çš„æ¶ˆæ¯ä¸­\n",
        "         messages = [SystemMessage(content=system_message)] + state[\"messages\"] \n",
        "     \n",
        "     else: \n",
        "         messages = state[\"messages\"] \n",
        "     \n",
        "     response = model.invoke(messages) \n",
        "     return {\"messages\": response}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
      "metadata": {},
      "source": [
        "We'll define a node to produce a summary.\n",
        "\n",
        "æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹æ¥ç”Ÿæˆæ‘˜è¦ã€‚\n",
        "\n",
        "Note, here we'll use `RemoveMessage` to filter our state after we've produced the summary.\n",
        "\n",
        "è¯·æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨ `RemoveMessage` åœ¨ç”Ÿæˆæ‘˜è¦åè¿‡æ»¤æˆ‘ä»¬çš„çŠ¶æ€ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_conversation(state: State): \n",
        "     \n",
        "     # é¦–å…ˆï¼Œæˆ‘ä»¬è·å–ä»»ä½•ç°æœ‰çš„æ‘˜è¦\n",
        "     summary = state.get(\"summary\", \"\") \n",
        " \n",
        "     # åˆ›å»ºæˆ‘ä»¬çš„æ‘˜è¦æç¤º\n",
        "     if summary: \n",
        "         \n",
        "         # æ‘˜è¦å·²å­˜åœ¨\n",
        "         summary_message = ( \n",
        "             f\"è¿™æ˜¯è¿„ä»Šä¸ºæ­¢å¯¹è¯çš„æ‘˜è¦ï¼š{summary}\\n\\n\" \n",
        "             \"è¯·ç»“åˆä»¥ä¸Šæ–°æ¶ˆæ¯æ‰©å±•æ‘˜è¦ï¼š\" \n",
        "         ) \n",
        "         \n",
        "     else: \n",
        "         summary_message = \"åˆ›å»ºä»¥ä¸Šå¯¹è¯çš„æ‘˜è¦ï¼š\" \n",
        " \n",
        "     # å°†æç¤ºæ·»åŠ åˆ°æˆ‘ä»¬çš„å†å²è®°å½•ä¸­\n",
        "     messages = state[\"messages\"] + [HumanMessage(content=summary_message)] \n",
        "     response = model.invoke(messages) \n",
        "     \n",
        "     # åˆ é™¤é™¤æœ€è¿‘2æ¡æ¶ˆæ¯å¤–çš„æ‰€æœ‰æ¶ˆæ¯\n",
        "     delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]] \n",
        "     return {\"summary\": response.content, \"messages\": delete_messages} "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
      "metadata": {},
      "source": [
        "We'll add a conditional edge to determine whether to produce a summary based on the conversation length.\n",
        "\n",
        "æˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªæ¡ä»¶è¾¹ï¼Œä»¥æ ¹æ®å¯¹è¯é•¿åº¦ç¡®å®šæ˜¯å¦ç”Ÿæˆæ‘˜è¦ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.types import Command\n",
        "\n",
        "def should_continue(state: State) -> Command:\n",
        "    \"\"\"è¿”å›è¦æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # å¦‚æœæ¶ˆæ¯è¶…è¿‡å…­æ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ€»ç»“å¯¹è¯\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "\n",
        "    # å¦åˆ™æˆ‘ä»¬å°±å¯ä»¥ç»“æŸäº†\n",
        "    return END\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
      "metadata": {},
      "source": [
        "## æ·»åŠ å†…å­˜ï¼ˆAdding memoryï¼‰\n",
        "\n",
        "Recall that [state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) to a single graph execution.\n",
        "\n",
        "å›å¿†ä¸€ä¸‹ï¼Œ[state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) å¯¹åº”å•ä¸€å›¾æ‰§è¡Œã€‚\n",
        "\n",
        "This limits our ability to have multi-turn conversations with interruptions. \n",
        "\n",
        "è¿™é™åˆ¶äº†æˆ‘ä»¬è¿›è¡Œå¸¦æœ‰ä¸­æ–­çš„å¤šè½®å¯¹è¯çš„èƒ½åŠ›ã€‚\n",
        "\n",
        "As introduced at the end of Module 1, we can use [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) to address this! \n",
        " \n",
        "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
        "\n",
        "æ­£å¦‚åœ¨ç¬¬1æ¨¡å—æœ«å°¾ä»‹ç»çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼  \n",
        "\n",
        "LangGraph å¯ä»¥ä½¿ç”¨æ£€æŸ¥ç‚¹å·¥å…·è‡ªåŠ¨ä¿å­˜æ¯ä¸€æ­¥ä¹‹åçš„å›¾çŠ¶æ€ã€‚\n",
        "\n",
        "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update. \n",
        "\n",
        "è¿™ä¸€å†…ç½®çš„æŒä¹…åŒ–å±‚ä¸ºæˆ‘ä»¬æä¾›äº†å†…å­˜æ”¯æŒï¼Œä½¿ LangGraph èƒ½å¤Ÿä»æœ€åä¸€æ¬¡çŠ¶æ€æ›´æ–°å¤„ç»§ç»­è¿è¡Œã€‚\n",
        "\n",
        "As we previously showed, one of the easiest to work with is `MemorySaver`, an in-memory key-value store for Graph state.\n",
        "\n",
        "æ­£å¦‚æˆ‘ä»¬ä¹‹å‰å±•ç¤ºçš„ï¼Œå…¶ä¸­ä¸€ä¸ªæœ€å®¹æ˜“ä½¿ç”¨çš„æ˜¯ `MemorySaver`ï¼Œä¸€ä¸ªç”¨äºå›¾å½¢çŠ¶æ€çš„å†…å­˜é”®å€¼å­˜å‚¨ã€‚\n",
        "\n",
        "All we need to do is compile the graph with a checkpointer, and our graph has memory!\n",
        "\n",
        "æˆ‘ä»¬éœ€è¦åšçš„åªæ˜¯ç”¨æ£€æŸ¥ç‚¹ç¼–è¯‘å™¨ç¼–è¯‘å›¾ï¼Œç„¶åæˆ‘ä»¬çš„å›¾å°±å…·å¤‡äº†è®°å¿†åŠŸèƒ½ï¼\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(\"summarize_conversation\",summarize_conversation)\n",
        "\n",
        "# Set the entrypoint as conversation\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
      "metadata": {},
      "source": [
        "## çº¿ç¨‹ï¼ˆThreadsï¼‰\n",
        "\n",
        "The checkpointer saves the state at each step as a checkpoint.\n",
        "\n",
        "æ£€æŸ¥ç‚¹ä¿å­˜å™¨åœ¨æ¯ä¸€æ­¥å°†çŠ¶æ€ä¿å­˜ä¸ºä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚\n",
        "\n",
        "These saved checkpoints can be grouped into a `thread` of conversation.\n",
        "\n",
        "è¿™äº›ä¿å­˜çš„æ£€æŸ¥ç‚¹å¯ä»¥è¢«åˆ†ç»„ä¸ºä¸€ä¸ª `thread` å¯¹è¯ã€‚\n",
        "\n",
        "Think about Slack as an analog: different channels carry different conversations.\n",
        "\n",
        "å°† Slack ä½œä¸ºç±»æ¯”æ¥æ€è€ƒï¼šä¸åŒçš„é¢‘é“æ‰¿è½½ç€ä¸åŒçš„å¯¹è¯ã€‚\n",
        "\n",
        "Threads are like Slack channels, capturing grouped collections of state (e.g., conversation).\n",
        "\n",
        "çº¿ç¨‹ç±»ä¼¼äº Slack é¢‘é“ï¼Œæ•è·æˆç»„çš„çŠ¶æ€é›†åˆï¼ˆä¾‹å¦‚ï¼Œå¯¹è¯ï¼‰ã€‚\n",
        "\n",
        "Below, we use `configurable` to set a thread ID.\n",
        "\n",
        "ä¸‹é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨ `configurable` æ¥è®¾ç½®çº¿ç¨‹ IDã€‚\n",
        "\n",
        "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "ä½ å¥½ï¼Œå¼ é”¡å†›ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œé˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€è¿›è¡Œé€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰ä»»åŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "é‚£å¤ªæ£’äº†ï¼æ¸¸æˆæ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„é¢†åŸŸã€‚ä½ å¹³æ—¶å–œæ¬¢ç©ä»€ä¹ˆç±»å‹çš„æ¸¸æˆå‘¢ï¼Ÿæ˜¯åŠ¨ä½œã€å†’é™©ã€è§’è‰²æ‰®æ¼”ï¼Œè¿˜æ˜¯ç­–ç•¥ç±»æ¸¸æˆï¼Ÿå¦‚æœä½ æœ‰å–œæ¬¢çš„æ¸¸æˆï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€èµ·è®¨è®ºæˆ–è€…åˆ†äº«ä¸€äº›æ¸¸æˆå¿ƒå¾—å“¦ï¼ğŸ˜Š\n"
          ]
        }
      ],
      "source": [
        "# Create a thread\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"ä½ å¥½æˆ‘æ˜¯å¼ é”¡å†›\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config) \n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()\n",
        "\n",
        "input_message = HumanMessage(content=\"ä½ æ˜¯è°\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config) \n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()\n",
        "\n",
        "input_message = HumanMessage(content=\"æˆ‘å–œæ¬¢ç©æ¸¸æˆ\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config) \n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
      "metadata": {},
      "source": [
        "Now, we don't yet have a summary of the state because we still have < = 6 messages.\n",
        "\n",
        "ç°åœ¨ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰çŠ¶æ€æ‘˜è¦ï¼Œå› ä¸ºæˆ‘ä»¬ä»ç„¶æœ‰ < = 6 æ¡æ¶ˆæ¯ã€‚\n",
        "\n",
        "This was set in `should_continue`. \n",
        "\n",
        "è¿™è¢«è®¾ç½®åœ¨ `should_continue`ã€‚\n",
        "\n",
        "```\n",
        "    # If there are more than six messages, then we summarize the conversation\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "```\n",
        "\n",
        "We can pick up the conversation because we have the thread.\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥ç»§ç»­å¯¹è¯ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰çº¿ç´¢ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.get_state(config).values.get(\"summary\",\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "068a93e9-f716-4980-8edf-94115017d865",
      "metadata": {},
      "source": [
        "The `config` with thread ID allows us to proceed from the previously logged state!\n",
        "\n",
        "å¸¦æœ‰ `config` çº¿ç¨‹ ID è®©æˆ‘ä»¬èƒ½å¤Ÿä»ä¹‹å‰è®°å½•çš„çŠ¶æ€ç»§ç»­ï¼\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "å½“ç„¶çŸ¥é“ï¼ã€Šè‹±é›„è”ç›Ÿã€‹ï¼ˆLeague of Legendsï¼Œç®€ç§° **LOL**ï¼‰æ˜¯ä¸€æ¬¾éå¸¸å—æ¬¢è¿çš„å¤šäººåœ¨çº¿æˆ˜æœ¯ç«æŠ€æ¸¸æˆï¼ˆMOBAï¼‰ï¼Œç”±Riot Gameså¼€å‘ã€‚ç©å®¶åœ¨æ¸¸æˆä¸­æ‰®æ¼”â€œå¬å”¤å¸ˆâ€ï¼Œæ“æ§æ‹¥æœ‰ç‹¬ç‰¹æŠ€èƒ½çš„è‹±é›„ï¼Œåœ¨ä¸€ä¸ªåä¸ºå¬å”¤å¸ˆå³¡è°·çš„åœ°å›¾ä¸Šä¸æ•Œæ–¹é˜Ÿä¼å¯¹æŠ—ï¼Œç›®æ ‡æ˜¯é€šè¿‡å›¢é˜Ÿåˆä½œå’Œç­–ç•¥æ¨å€’æ•Œæ–¹ä¸»åŸºåœ°ã€‚\n",
            "\n",
            "ä½ ç©äº†å¤šä¹…å•¦ï¼Ÿæœ‰ç‰¹åˆ«å–œæ¬¢çš„è‹±é›„æˆ–è€…ä½ç½®ï¼ˆæ¯”å¦‚ä¸Šå•ã€æ‰“é‡ã€ä¸­å•ã€ADã€è¾…åŠ©ï¼‰å—ï¼Ÿå¦‚æœä½ æ„¿æ„åˆ†äº«ï¼Œæˆ‘å¯ä»¥é™ªä½ èŠèŠæ¸¸æˆå¿ƒå¾—ï¼Œæˆ–è€…å¸®ä½ åˆ†æå¯¹å±€å“¦ï¼ğŸ®ğŸ˜„\n"
          ]
        }
      ],
      "source": [
        "input_message = HumanMessage(content=\"æˆ‘å–œæ¬¢ç©lolï¼Œä½ çŸ¥é“è¿™ä¸ªæ¸¸æˆå—\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config) \n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ä»¥ä¸‹æ˜¯å¯¹ä»¥ä¸Šå¯¹è¯çš„ç®€è¦æ‘˜è¦ï¼š\\n\\nç”¨æˆ·æ˜¯å¼ é”¡å†›ï¼Œä»–è¡¨ç¤ºè‡ªå·±å–œæ¬¢ç©æ¸¸æˆï¼Œç‰¹åˆ«æ˜¯ã€Šè‹±é›„è”ç›Ÿã€‹ï¼ˆLOLï¼‰ã€‚ä»–ç¡®è®¤äº†é€šä¹‰åƒé—®å¯¹è¿™æ¬¾æ¸¸æˆçš„äº†è§£ã€‚é€šä¹‰åƒé—®ä½œä¸ºé˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œä¸ä»…èƒ½å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ï¼Œè¿˜èƒ½è¿›è¡Œé€»è¾‘æ¨ç†å’Œç¼–ç¨‹ç­‰ä»»åŠ¡ã€‚å¯¹è¯ä¸­ä½“ç°äº†ç”¨æˆ·å¯¹æ¸¸æˆçš„å…´è¶£ï¼Œä»¥åŠå¸Œæœ›åœ¨æ¸¸æˆæ–¹é¢è·å¾—æ›´å¤šäº’åŠ¨ä¸å¸®åŠ©çš„æ„æ„¿ã€‚'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.get_state(config).values.get(\"summary\",\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
      "metadata": {},
      "source": [
        "## æœ—å²å¯†æ–¯ï¼ˆLangSmithï¼‰\n",
        "\n",
        "Let's review the trace!\n",
        "\n",
        "è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹traceï¼\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
